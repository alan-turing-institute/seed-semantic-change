{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a work-in-progress notebook\n",
    "\n",
    "We wish to know this:\n",
    "\n",
    "1. How well does the model identify the correct number of senses for the target word?\n",
    "2. **How well does the model identify the correct senses for the target word?**\n",
    "3. **How well does the model assign the right words to a given sense of the target word?**\n",
    "4. How well does the model assign the senses to the time intervals for the target word?\n",
    "\n",
    "The script will evaluate **Q2** and **Q3**. Q4 will follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filenames of different model outputs must be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target ID: 69419\n",
      "Window size: 5 <class 'int'>\n",
      "Iterations: 100 <class 'int'>\n",
      "Start time: -430 <class 'int'>\n",
      "End time: 359 <class 'int'>\n",
      "Time interval: 100 <class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic variables and imports:\n",
    "\n",
    "import codecs, csv, os, time, re, io\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from  more_itertools import unique_everseen\n",
    "\n",
    "# directories\n",
    "dir_in = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), \"evaluation\", \"evaluation_input\"))\n",
    "dir_out = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), \"evaluation\", \"evaluation_output\"))\n",
    "dir_parameter = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), \"src\", \"dynamic-senses\",\"greek_input\",\"all_parameters\"))\n",
    "\n",
    "\n",
    "s_senses = io.open(dir_in+\"/senses_69419.txt\",\"r\")\n",
    "k_senses = io.open(dir_in+\"/mus.dat\",\"r\")\n",
    "parameter_file = io.open(dir_parameter+\"/params_v1.txt\",\"r\")\n",
    "\n",
    "target_id = os.path.basename(s_senses.name)\n",
    "target_id = target_id.replace(\"senses_\",\"\")\n",
    "target_id = target_id.replace(\".txt\",\"\")\n",
    "print(\"Target ID:\",target_id)\n",
    "\n",
    "param_name = os.path.basename(parameter_file.name)\n",
    "param_name = param_name.replace(\"params\",\"\")\n",
    "\n",
    "\n",
    "results_file = io.open(dir_out+\"/\"+target_id+param_name,\"w\")\n",
    "\n",
    "# DEBUG:\n",
    "#s_senses = io.open(dir_in+\"/senses_69419_debug.txt\",\"r\")\n",
    "#k_senses = io.open(dir_in+\"/mus_debug.dat\",\"r\")\n",
    "# k0 = mus4\n",
    "# k1 = mus3\n",
    "# k2 = mus2\n",
    "# k3 = mus1\n",
    "# k4 = nothing\n",
    "\n",
    "\n",
    "\n",
    "file_senses = s_senses.readlines()[1:]\n",
    "output_senses = k_senses.read()\n",
    "\n",
    "i = 0\n",
    "for line in parameter_file.readlines():\n",
    "    i+=1\n",
    "    if i == 4:\n",
    "        line = line.split(\"\\t\")\n",
    "        window_size = int(line[1])\n",
    "        print(\"Window size:\",window_size,type(window_size))\n",
    "        \n",
    "    if i == 13:\n",
    "        line = line.split(\"\\t\")\n",
    "        iterations = int(line[1])\n",
    "        print(\"Iterations:\",iterations,type(iterations))\n",
    "        \n",
    "    if i == 14:\n",
    "        line = line.split(\"\\t\")\n",
    "        start_time = int(line[1])\n",
    "        print(\"Start time:\",start_time,type(start_time))\n",
    "        \n",
    "    if i == 15:\n",
    "        line = line.split(\"\\t\")\n",
    "        end_time = int(line[1])\n",
    "        print(\"End time:\",end_time,type(end_time))\n",
    "    \n",
    "    if i == 16:\n",
    "        line = line.split(\"\\t\")\n",
    "        time_interval = int(line[1])\n",
    "        print(\"Time interval:\",time_interval,type(time_interval))\n",
    "\n",
    "results_file.write(\"Target ID %s Window size %s Start time %s End time %s Time Interval %s Iterations %s\\n\" % (target_id,window_size,start_time,end_time,time_interval,iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "100\n",
      "-430 359\n"
     ]
    }
   ],
   "source": [
    "# Defining time periods from the output file\n",
    "\n",
    "total_years = end_time-start_time\n",
    "perioddd = 0\n",
    "temp_start_time = start_time\n",
    "\n",
    "for year in range(temp_start_time,end_time):\n",
    "    if temp_start_time + time_interval < end_time:\n",
    "        perioddd +=1\n",
    "        print(perioddd)\n",
    "        temp_start_time += time_interval\n",
    "\n",
    "number_of_slices = perioddd # cfr above\n",
    "\n",
    "slice_duration = time_interval # read from the parameter file\n",
    "print(slice_duration)\n",
    "\n",
    "print(start_time,end_time)\n",
    "\n",
    "slice_years = dict()\n",
    "\n",
    "for period in range(0,number_of_slices):\n",
    "    slice_years[period] = list()\n",
    "    \n",
    "    if period == number_of_slices-1:\n",
    "        for i in range(latest_i,end_time):\n",
    "            slice_years[period].append(i)  \n",
    "    \n",
    "    if period != number_of_slices-1:\n",
    "        for i in range(start_time,end_time):\n",
    "        \n",
    "            if i > int(period*slice_duration) + start_time:\n",
    "                if i < int((period+1)*slice_duration) + start_time:\n",
    "                    slice_years[period].append(i)\n",
    "                    latest_i = i\n",
    "#print(slice_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- ~~create the notebook~~\n",
    "- ~~organise the notebook~~\n",
    "- ~~write \"general idea\" pseudocode for the evaluation~~\n",
    "- ~~get input files~~\n",
    "- ~~figure out data structures to store the variables~~\n",
    "- ~~write actual code~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: How well does the model identify the correct senses for the target word?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-462-82fa54601c9a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-462-82fa54601c9a>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for each k:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# For each target word, we have a list of senses  s (given by the expert)\n",
    "# For each target word, we have a list of senses k (given by the model)\n",
    "# This Q consists in matching s and k, and doing so in a confident way --> confidence score\n",
    "\n",
    "for each k:\n",
    "    for each s:\n",
    "        create conf(k,s)\n",
    "\n",
    "# What is conf(k,s)?\n",
    "        conf(k,s) = (p1*match(w1,s)+p2*match(w1,s)+px(wx,s))/10 WHERE\n",
    "    \n",
    "            px = probability of word wx \n",
    "                \n",
    "                and\n",
    "            \n",
    "            match(wx,s) =   1/number_of_senses_assigned_to_wx if s_is_one_of_them \n",
    "            \n",
    "                    or \n",
    "                            0 if w_is_not_associated_to_s\n",
    "                \n",
    "# Once we have gone through all s for one k, we have to choose the best k for s. How? (TBD, cfr Valerio and Barbara)\n",
    "\n",
    "# Once all ks have been assigned to all ss (or NA), we can calculate a general confidence score for the model.\n",
    "# One easy way to do that: \n",
    "\n",
    "conf_score_model = number_of_non_NA/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real code\n",
    "\n",
    "Steps:\n",
    "\n",
    "- extract all senses from the file\n",
    "- use those senses as keys for a dictionary, `dict_of_words`\n",
    "- fill the dictionary: for each key, we store a list of words pertaining to that sense\n",
    "- transform the lists as sets so as to remove duplicates within the same sense\n",
    "- create a dictionary with a word as a key and its weight as a value, depending on how many senses it appears\n",
    "- parse the model output and get the probability weights for each word\n",
    "- do not take into account the first line\n",
    "- take care of empty lines\n",
    "\n",
    "Todo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET ['NA', 'mus-4', 'mus-1', 'mus-2']\n",
      "ITERTOOLS ['mus-1', 'NA', 'mus-4', 'mus-2']\n",
      "Number of senses: 4 ['mus-1', 'NA', 'mus-4', 'mus-2']\n",
      "mus-1\n",
      "i 0 sense mus-1 number of words 549\n",
      "words {'105344', '45917', '29624', '40001', '95221', '64448', '15378', '68174', '93812', '104655', '108537', '72627', '17381', '46966', '116058', '85417', '55499', '7832', '52095', '7561', '61176', '26048', '77699', '53161', '116050', '100965', '56003', '73277', '21830', '74126', 'nlsj71743', '18937', '80327', 'nlsj86496', '74819', '39190', '42890', '72273', '7529', '113556', '82665', '8665', '49506', '67974', 'nlsj114757', '98241', '23468', '14362', '70105', '26032', 'nlsj11198', '4778', '11206', '4493', '96979', '104872', '76184', '73128', '110089', '89366', '22100', 'nlsj61205', '63827', '11305', '12641', '28566', '48341', '112943', '2583', '4548', '71262', '73221', '103152', '3289', '35570', '93388', '9757', '63352', '57262', '116244', 'nlsj47984', '62205', '7724', '53956', '48670', 'nlsj8671', '66173', '42827', '98723', '80555', '31562', '62528', '75910', '112347', '13608', '91944', '106566', '68791', '114615', '33956', '39195', '436', '12035', '39847', '114731', '84725', '110639', '83760', '35267', '18271', 'nlsj4012', '75263', 'nlsj96033', '114842', '59124', '85306', '106114', '49589', '97147', '46123', '34476', 'nlsj43224', '45980', '104690', '23690', '41082', '48291', '52571', '112720', '112833', '54946', '38743', '34855', '88498', '67762', '10933', '71559', '31236', '108780', '12176', '37616', '7612', '112769', '15763', 'nlsj78558', '78746', '35708', '43206', '74571', 'nlsj68688', '18706', '104355', '3800', '47917', '49437', '11970', 'nlsj4113', '15618', '36165', '42842', '63814', '88716', '2224', '31161', '55498', '24261', '71308', '65552', '51849', '37488', '7159', '51373', '79223', '50073', '111207', '110484', '104421', '76530', '19972', '106974', '83774', '15162', '53442', '82954', '20945', 'nlsj9526', '26197', '15380', '46646', '104538', 'nlsj32160', '32686', '107959', '114587', '64956', 'nlsj32167', '69469', '38732', '22209', '52460', '23283', 'nlsj98815', '90504', '67868', '112559', '26114', '45513', '110655', '72202', '19268', '70477', 'nlsj68228', '55532', '65565', '19282', '18166', '72275', '109687', '85672', '114847', 'nlsj10130', '108882', '51376', '88464', '105176', '29883', '26233', '109403', '41619', '39313', '66494', '76431', '13427', 'nlsj4320', '27629', '30911', '47513', '27415', '6449', '79947', '67485', '80761', '45996', '50093', '84494', '5607', '11058', '12973', '53942', '43305', '69052', '69252', '98312', '75352', '21431', '56810', '29962', '95368', 'nlsj57918', 'nlsj40053', '34366', '91800', '12948', '50679', '21783', '6684', '59276', '112472', '37274', '116470', '17007', '63143', '76564', '66639', '51358', '36390', '58478', '40156', '47964', '105816', 'nlsj40132', '19546', '2219', '103871', '5112', '36790', '75306', '28355', '25870', '69036', '71314', '111895', '16400', '51256', '4845', '84150', '5132', '71673', '79697', '64586', '89309', '67104', '26499', '66294', '21920', 'nlsj7583', '93796', 'nlsj2729', '86429', '114688', '48770', '21335', '68970', '8909', '15893', 'nlsj12527', '463', '114972', 'nlsj801', '76703', '116416', '83253', '22739', '55997', '47876', '74735', '38547', '98173', '47447', '113560', '84534', '105550', '86305', '66777', '40545', 'nlsj106503', '54592', '102381', 'nlsj59923', '47617', '65089', '27764', '21487', '34848', '62204', '95258', '4068', '19711', '7182', '71065', '53695', '14181', '72928', '1564', '115845', '16171', '83928', '75552', '51727', '103922', '24444', '84234', '113711', '23678', '22036', '65697', '28360', '35710', '8586', '17962', '93536', '29828', '18334', '63845', '65983', '5009', '19641', '20728', '64316', '98234', '83718', '4927', '101716', '25018', '40161', '92171', '12409', '72287', '11229', '2671', '61040', '31709', '49227', '31964', '76157', '90329', '34372', '59708', 'nlsj6617', '113741', '115810', '49331', 'nlsj5904', 'nlsj10580', '110114', '37711', 'nlsj8970', '1984', '37851', '110598', '114548', '103942', '51241', '65975', '104311', '54812', '2834', '23658', '83434', '70958', '62303', '7177', '2061', '41705', '7062', 'nlsj52509', '83113', '6384', '95074', '94316', '678', '106502', 'nlsj8979', 'nlsj5738', '3398', '42686', '76335', '65097', '46195', '110027', '26447', '77698', '63713', '114706', '110284', 'nlsj106628', '42659', '41536', '26684', '38966', '103957', '113251', '7779', '83266', '98031', '83251', '33241', '13098', '69419', '95523', '83665', '31556', '110302', '80239', 'nlsj60710', '15121', '93022', '4274', '59005', '116293', '36571', '62816', '48867', '47665', '56406', 'nlsj69856', '42887', '112169', '115193', '92406', '79103', '41538', '112070', '51647', '70768', '75316', '84422', '19788', '49875', '32657', '86352', '55139', 'nlsj100912', '25007', '83756', '83869', '24226', '84552', '34071', '61791', '83783', '116059', '68641', '18128', '31948', '60402', '75954', '20674', '24856', '16609', '3241', '82959', '92162', '28036', '51815', '1083', '12349', '46804', '25402', '3327', 'nlsj96345', '71118', '14050', '94474', '8505', '33770', '51300', '22882', '41633', '94713', '41502', '21589', '52035', '21901', '66746', '108536', '49955', '113823', '69863', '52332', 'nlsj80462', '95522', '45671', '6174', '70708', '67250', '103637', '13039', 'nlsj4784'}\n",
      "\n",
      "\n",
      "\n",
      "NA\n",
      "i 1 sense NA number of words 0\n",
      "words set()\n",
      "\n",
      "\n",
      "\n",
      "mus-4\n",
      "i 2 sense mus-4 number of words 193\n",
      "words {'79069', '14269', '10933', '67762', '85665', '102676', '58142', '55497', '115748', '74621', '83732', '111722', '93812', '108780', '114083', '55313', 'nlsj79694', '11583', '15609', '83834', '24289', '90334', '41271', '114653', '3630', '37720', '65191', '115887', '61176', '6898', '53015', '75989', '104355', '115212', '36216', '13376', 'nlsj71743', 'nlsj42558', '42071', '18790', '116218', '7608', '51369', '83174', '99647', '101714', '57460', 'nlsj82141', '26002', '90166', '2392', '65552', '15893', '108652', '69419', '22210', '116416', '101851', '116408', '97605', '20885', '87413', '36938', '83665', '61245', 'nlsj40134', '109733', '70495', '73672', '27092', '4493', '74735', '95961', '113560', '90347', '48504', '19972', '112703', '1199', '71984', '50521', '71373', '63550', '85099', '84534', '51785', 'nlsj82490', '13985', '39016', '20621', '100964', '71585', '16051', '43975', '106676', 'nlsj33345', '75595', '66342', '68996', '22209', '57457', '74752', '114753', '90504', '19528', '97241', '82190', '35570', '93388', '26039', '83869', 'nlsj177', '66750', '31609', '66389', '15011', '67526', '109729', '31607', '18062', '101034', '75552', '68641', '57466', '29883', '36180', '84234', '31562', '102795', '39543', '14266', '37405', '112794', '63772', '70521', '98234', '93341', '33969', '50908', '20836', '13852', '33770', '103085', '113477', '100379', '45996', '21651', '24184', '91634', '4474', '58429', '57474', '4470', '11058', '7793', '85953', '96560', '69532', '85306', '35244', '42214', '621', '66295', 'nlsj112819', '33426', '85876', '44660', '102000', '22660', '104690', '39180', '6339', '98417', '26034', '55391', '97606', '96698', '39299', '67009', '64703', '111764', '37961', '51241', '74378', '93332', '52571', '112720', '100495', '13039', '34982', 'nlsj35116', '37726', '71404'}\n",
      "\n",
      "\n",
      "\n",
      "mus-2\n",
      "i 3 sense mus-2 number of words 112\n",
      "words {'54990', '66342', '2586', '75992', 'nlsj7772', 'nlsj99416', '49875', '67762', '82758', '22316', 'nlsj61519', '68539', '93388', '62274', '98955', '113881', '57262', '32263', '90303', '34243', '49444', '58262', 'nlsj86871', '65565', '19789', '85672', '65544', 'nlsj76740', '60878', '45525', '80525', '29390', '83209', '19236', '83212', '76910', 'nlsj4249', '38744', '97266', '74126', '47745', '15198', '16440', '66494', '112811', '105557', '53254', '26328', '53222', '214', '22389', '104624', '29134', '110639', 'nlsj75531', 'nlsj68042', '17228', '51737', '4698', '7362', '100673', '45182', '4763', '45526', '64559', '30569', '65552', '57356', '45996', '69419', '94967', 'nlsj114757', '58429', '101982', '4670', '20413', 'nlsj8425', 'nlsj6085', '68144', '68185', '73672', '60316', 'nlsj3887', '23861', '93880', '60317', 'nlsj3072', '89321', '75653', '45980', '102930', '67364', '33822', 'nlsj3264', '4562', '59121', '58271', '21168', '102474', 'nlsj70384', 'nlsj29538', '64642', '103773', '62258', '106267', '74378', '52571', '75652', '70768', '65934', '68706', 'nlsj10103'}\n",
      "\n",
      "\n",
      "\n",
      "sentences smaller than window size 5 : 178\n",
      "number of NA words: 136\n",
      "same? 136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_senses = list() # list where we store all sense ids provided by expert\n",
    "#sense_for_period_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for line in file_senses: \n",
    "    cells = line.split(\"\\t\")\n",
    "    sense = cells[11] # The sense ID is after the 10th tab\n",
    "    if sense != 'w':\n",
    "        \n",
    "        \n",
    "        if int(cells[12]) == 1:   ## we only take the senses annotated because of collocates and nothing else\n",
    "            #print(int(s[12]))\n",
    "            expert_senses.append(sense)\n",
    "              \n",
    "        else:\n",
    "            expert_senses.append(\"NA\") # if the reason for finding the sense is not \"collocates\" (1), the sense NA is created\n",
    "\n",
    "\n",
    "#print(len(expert_senses),expert_senses,len(set(expert_senses)))\n",
    "\n",
    "\n",
    "expert_senses_set = list(set(expert_senses)) # we only keep the unique senses\n",
    "expert_senses = list(unique_everseen(expert_senses))\n",
    "print(\"SET\",expert_senses_set)\n",
    "print(\"ITERTOOLS\",expert_senses)\n",
    "\n",
    "number_of_s = len(expert_senses)  # we create a variable that stores the number of unique senses\n",
    "print(\"Number of senses:\",number_of_s,expert_senses)\n",
    "\n",
    "# This dictionary has a sense as a key, and a list of words as a value. \n",
    "dict_of_words = dict()\n",
    "# This list stores all words\n",
    "list_of_all_words = list()\n",
    "# This dictionary stores all words as keys and their weight as value\n",
    "word_weight = dict()\n",
    "# This dictionary stores the number of times a sense appears in a slice\n",
    "sense_date_amount = dict()\n",
    "\n",
    "# This list stores words in w and not collocates senses\n",
    "list_of_NA_words = list()\n",
    "# This dictionary stores words in w and not collocates senses\n",
    "word_weight_NA = dict()\n",
    "dummy_counter = 0\n",
    "\n",
    "\n",
    "sentences_smaller_than_window_size = 0\n",
    "\n",
    "for i in range(0,number_of_s): # for each sense, we create a dictionary entry which has a list as value\n",
    "#for i in range(2,3):\n",
    "    dict_of_words[expert_senses[i]] = list()\n",
    "    print(expert_senses[i])\n",
    "\n",
    "    for line in file_senses: # we go back in the file\n",
    "        cells = line.split(\"\\t\") # splitting on tabs\n",
    "        if int(cells[12]) == 1:  # senses inferred from collocates\n",
    "            if cells[11] == expert_senses[i]:      # we store all words for one sense \n",
    "                \n",
    "        \n",
    "                sentence_of_ids = cells[8] # 8 is for IDs, 9 is for words\n",
    "                list_of_ids = sentence_of_ids.split(\" \")  # splitting on spaces\n",
    "        \n",
    "        \n",
    "                index_of_target = list_of_ids.index(target_id) # getting the location of the target word in the collocates\n",
    "                list_of_ids_window = list()\n",
    "                for n in range(index_of_target-window_size,index_of_target+window_size+1): # for every word in the window_size range\n",
    "                    try:   # if there's a word it's taken into account\n",
    "\n",
    "                        list_of_ids_window.append(list_of_ids[n])\n",
    "                \n",
    "                    except IndexError: # if there isn't, too bad\n",
    "                        sentences_smaller_than_window_size += 1\n",
    "\n",
    "                for word_id in list_of_ids_window:\n",
    "                    if int(cells[12]) == 1:\n",
    "                        \n",
    "                        \n",
    "                        if cells[11] == expert_senses[i]:  \n",
    "\n",
    "                            dict_of_words[expert_senses[i]].append(word_id)                    \n",
    "                            \n",
    "                    \n",
    "                    \n",
    "                    list_of_all_words.append(word_id) # we store all words, we'll iterate over that for scores\n",
    "            \n",
    "            \n",
    "            # if the sense is \"w\", the collocates are put in the \"NA words\"\n",
    "            \n",
    "            if cells[11] == \"w\":\n",
    "                #print(\"W\")\n",
    "                sentence_of_ids = cells[8] # 8 is for IDs, 9 is for words\n",
    "                list_of_ids = sentence_of_ids.split(\" \")  # splitting on spaces\n",
    "                index_of_target = list_of_ids.index(target_id) # getting the location of the target word in the collocates\n",
    "                list_of_ids_window = list()\n",
    "                for n in range(index_of_target-window_size,index_of_target+window_size+1): # for every word in the window_size range\n",
    "                    try:   # if there's a word it's taken into account\n",
    "\n",
    "                        list_of_NA_words.append(list_of_ids[n])\n",
    "                        list_of_all_words.append(list_of_ids[n])\n",
    "                    except IndexError:\n",
    "                        dummy_counter +=1\n",
    "                    \n",
    "        else:  # words that are in \"non collocates senses\"\n",
    "            #print(\"NON COLOC\")\n",
    "            sentence_of_ids = cells[8] # 8 is for IDs, 9 is for words\n",
    "            #print(sentence_of_ids)\n",
    "            list_of_ids = sentence_of_ids.split(\" \")  # splitting on spaces\n",
    "            index_of_target = list_of_ids.index(target_id) # getting the location of the target word in the collocates\n",
    "            #print(index_of_target)\n",
    "            list_of_ids_window = list()\n",
    "            #print(index_of_target-window_size,index_of_target+window_size+1)\n",
    "            for n in range(index_of_target-window_size,index_of_target+window_size+1): # for every word in the window_size range\n",
    "                try:   # if there's a word it's taken into account\n",
    "                    #print(list_of_ids_window)\n",
    "                    #print(list_of_ids[n])\n",
    "                    list_of_NA_words.append(list_of_ids[n])\n",
    "                    list_of_all_words.append(list_of_ids[n])\n",
    "                except IndexError:\n",
    "                        dummy_counter +=1\n",
    "            #print(list_of_NA_words)\n",
    "            \n",
    "            \n",
    "    # Here, we remove duplicates\n",
    "    #dict_of_words[expert_senses[i]].append(\"79223\") #testing\n",
    "    \n",
    "    dict_of_words[expert_senses[i]] = set(dict_of_words[expert_senses[i]])\n",
    "    \n",
    "    \n",
    "      \n",
    "    print(\"i\",i,\"sense\",expert_senses[i],\"number of words\",len(dict_of_words[expert_senses[i]]))\n",
    "    print(\"words\",set(dict_of_words[expert_senses[i]]))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "# NOW THAT WE HAVE A LIST OF NA WORDS \n",
    "# We can pyt that in the dict_of_words[expert_sense] dictionary\n",
    "#print(\"NA words\",list_of_NA_words)\n",
    "list_of_NA_words = set(list_of_NA_words)\n",
    "dict_of_words[\"NA\"] = list_of_NA_words\n",
    "\n",
    "print(\"sentences smaller than window size\",window_size,\":\",sentences_smaller_than_window_size)\n",
    "#print(\"dummy\",dummy_counter)\n",
    "print(\"number of NA words:\",len(list_of_NA_words))\n",
    "print(\"same?\",len(dict_of_words[\"NA\"]))\n",
    "\n",
    "results_file.write(\"Expert senses %s Total %s \" %(expert_senses,len(expert_senses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('mus-1', 0): 0, ('mus-1', 1): 0, ('mus-1', 2): 0, ('mus-1', 3): 0, ('mus-1', 4): 0, ('mus-1', 5): 0, ('mus-1', 6): 0, ('NA', 0): 0, ('NA', 1): 0, ('NA', 2): 0, ('NA', 3): 0, ('NA', 4): 0, ('NA', 5): 0, ('NA', 6): 0, ('mus-4', 0): 0, ('mus-4', 1): 0, ('mus-4', 2): 0, ('mus-4', 3): 0, ('mus-4', 4): 0, ('mus-4', 5): 0, ('mus-4', 6): 0, ('mus-2', 0): 0, ('mus-2', 1): 0, ('mus-2', 2): 0, ('mus-2', 3): 0, ('mus-2', 4): 0, ('mus-2', 5): 0, ('mus-2', 6): 0} \n",
      "\n",
      "{('mus-1', 0): 7, ('mus-1', 1): 3, ('mus-1', 2): 1, ('mus-1', 3): 3, ('mus-1', 4): 7, ('mus-1', 5): 24, ('mus-1', 6): 48, ('NA', 0): 0, ('NA', 1): 0, ('NA', 2): 0, ('NA', 3): 0, ('NA', 4): 0, ('NA', 5): 0, ('NA', 6): 0, ('mus-4', 0): 21, ('mus-4', 1): 1, ('mus-4', 2): 0, ('mus-4', 3): 1, ('mus-4', 4): 0, ('mus-4', 5): 1, ('mus-4', 6): 9, ('mus-2', 0): 0, ('mus-2', 1): 0, ('mus-2', 2): 0, ('mus-2', 3): 0, ('mus-2', 4): 0, ('mus-2', 5): 0, ('mus-2', 6): 22}\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "sense_date_amount = dict() # dict where we have the number of senses for [sense,period]\n",
    "\n",
    "# this dictionary is now initialised with 0 for each CORRECT sense,period pair we have\n",
    "for sense in expert_senses:\n",
    "    for period in slice_years.keys():\n",
    "        sense_date_amount[sense,period] = 0\n",
    "        \n",
    "print(sense_date_amount,\"\\n\")        \n",
    "\n",
    "counter = 0\n",
    "\n",
    "for line in file_senses: \n",
    "    #print(len(file_senses))\n",
    "    cells = line.split(\"\\t\")\n",
    "    sense = cells[11] # The sense ID is after the 10th tab\n",
    "    if sense != 'w':\n",
    "        #print(sense)\n",
    "        \n",
    "        \n",
    "        if int(cells[12]) == 1:   ## we only take the senses annotated because of collocates and nothing else\n",
    "            #print(int(s[12]))\n",
    "            #expert_senses.append(sense)\n",
    "            \n",
    "            for period in slice_years.keys():\n",
    "                if int(cells[0]) in slice_years[period]:\n",
    "                    #sense_for_period_counter += 1\n",
    "                    sense_date_amount[sense,period] += 1\n",
    "                    counter += 1\n",
    "                    \n",
    "print(sense_date_amount)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mus-1', 'NA', 'mus-4', 'mus-2']\n",
      "YO\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# For every word in the list of words that we have\n",
    "# we count the number of senses it appears in\n",
    "# we use that number to divide its importance: 1 sense = 1 importance; 2 senses = 0.5 importance\n",
    "# this can be finetuned\n",
    "\n",
    "print(expert_senses)\n",
    "#print(\"list_of_NA_words\",list_of_NA_words,\"\\n\\n\")\n",
    "#print(\"list of mus 1 words\",dict_of_words['mus-1'])\n",
    "\n",
    "word_weight_NA = dict()\n",
    "\n",
    "for word in list_of_all_words:\n",
    "#word = \"113560\"\n",
    "    x = 0\n",
    "    z = 0\n",
    "#print(word)\n",
    "    for i in range(0,number_of_s):\n",
    "        if word in dict_of_words[expert_senses[i]]:\n",
    "            if word == \"105344\":\n",
    "                print(\"YO\")\n",
    "                \n",
    "            if expert_senses[i] != \"NA\":\n",
    "                x += 1 \n",
    "                #print(\"froot the loop\")\n",
    "                \n",
    "\n",
    "    if x != 0:\n",
    "        word_weight[word] = float(1/x)\n",
    "        #print(word,\"this is a x!=0\",x,\"this is its weight\",float(1/x))\n",
    "        \n",
    "        if word in list_of_NA_words:\n",
    "            z = x + 1\n",
    "            #print(z)\n",
    "            #print(word,\"this is a z\",z,\"this is its weight\",float(1/z))\n",
    "            \n",
    "            word_weight_NA[word] = float(1/z)\n",
    "            \n",
    "    if x == 0:\n",
    "        word_weight_NA[word] = 1\n",
    "        word_weight[word] = 0  # with this we prevent the case that a word that is ONLY in NA has no weight \n",
    "  \n",
    "        \n",
    "    #else: \n",
    "    #    word_weight_NA[word] = word_weight[word]\n",
    "        \n",
    "#print(word_weight_NA)    \n",
    "#print(word,word_weight[word])\n",
    "\n",
    "#print(word_weight_NA[\"53826\"])\n",
    "\n",
    "#for key in word_weight_NA.keys():\n",
    "#    print(key,word_weight_NA[key])\n",
    "print(word_weight[\"105344\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parsing output.dat\n",
    "- split on \"===============  per time  ===============\" and keep first part\n",
    "- transform that into a list, then\n",
    "- get lines that start with \"p(w|s)\"\n",
    "- count those, k = that number\n",
    "- split the line on \":\", keep the second part\n",
    "- split the rest on \";\", it's [ID] = prob_from_this_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word id 28355 ; probability 0.088\n",
      "word id 69419 ; probability 0.069\n",
      "word id 57460 ; probability 0.056\n",
      "word id 114587 ; probability 0.042\n",
      "word id 42071 ; probability 0.041\n",
      "word id 35267 ; probability 0.035\n",
      "word id 51647 ; probability 0.035\n",
      "word id 64448 ; probability 0.023\n",
      "word id 45980 ; probability 0.018\n",
      "word id 53826 ; probability 0.017\n",
      "{'28355': 0.2075471698113207}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075, '64448': 0.05424528301886792}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075, '64448': 0.05424528301886792, '45980': 0.042452830188679236}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075, '64448': 0.05424528301886792, '45980': 0.042452830188679236, '53826': 0.04009433962264151}\n",
      "{'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075, '64448': 0.05424528301886792, '45980': 0.042452830188679236, '53826': 0.04009433962264151}\n",
      "word id 79223 ; probability 0.063\n",
      "word id 92927 ; probability 0.057\n",
      "word id 46574 ; probability 0.038\n",
      "word id 67660 ; probability 0.038\n",
      "word id 103085 ; probability 0.036\n",
      "word id 86112 ; probability 0.030\n",
      "word id 101982 ; probability 0.029\n",
      "word id 75808 ; probability 0.026\n",
      "word id 68539 ; probability 0.024\n",
      "word id 54607 ; probability 0.024\n",
      "{'79223': 0.17260273972602735}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587, '103085': 0.09863013698630134}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587, '103085': 0.09863013698630134, '86112': 0.08219178082191778}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587, '103085': 0.09863013698630134, '86112': 0.08219178082191778, '101982': 0.07945205479452053}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587, '103085': 0.09863013698630134, '86112': 0.08219178082191778, '101982': 0.07945205479452053, '75808': 0.07123287671232874}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587, '103085': 0.09863013698630134, '86112': 0.08219178082191778, '101982': 0.07945205479452053, '75808': 0.07123287671232874, '68539': 0.06575342465753423}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587, '103085': 0.09863013698630134, '86112': 0.08219178082191778, '101982': 0.07945205479452053, '75808': 0.07123287671232874, '68539': 0.06575342465753423, '54607': 0.06575342465753423}\n",
      "{'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587, '103085': 0.09863013698630134, '86112': 0.08219178082191778, '101982': 0.07945205479452053, '75808': 0.07123287671232874, '68539': 0.06575342465753423, '54607': 0.06575342465753423}\n",
      "word id 62258 ; probability 0.080\n",
      "word id 64586 ; probability 0.052\n",
      "word id 58271 ; probability 0.048\n",
      "word id nlsj86871 ; probability 0.041\n",
      "word id 101851 ; probability 0.039\n",
      "word id nlsj183 ; probability 0.037\n",
      "word id 75653 ; probability 0.031\n",
      "word id nlsj59923 ; probability 0.030\n",
      "word id 70105 ; probability 0.026\n",
      "word id 82758 ; probability 0.024\n",
      "{'62258': 0.19607843137254902}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941, 'nlsj86871': 0.10049019607843138}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941, 'nlsj86871': 0.10049019607843138, '101851': 0.09558823529411764}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941, 'nlsj86871': 0.10049019607843138, '101851': 0.09558823529411764, 'nlsj183': 0.0906862745098039}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941, 'nlsj86871': 0.10049019607843138, '101851': 0.09558823529411764, 'nlsj183': 0.0906862745098039, '75653': 0.07598039215686274}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941, 'nlsj86871': 0.10049019607843138, '101851': 0.09558823529411764, 'nlsj183': 0.0906862745098039, '75653': 0.07598039215686274, 'nlsj59923': 0.07352941176470587}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941, 'nlsj86871': 0.10049019607843138, '101851': 0.09558823529411764, 'nlsj183': 0.0906862745098039, '75653': 0.07598039215686274, 'nlsj59923': 0.07352941176470587, '70105': 0.06372549019607843}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941, 'nlsj86871': 0.10049019607843138, '101851': 0.09558823529411764, 'nlsj183': 0.0906862745098039, '75653': 0.07598039215686274, 'nlsj59923': 0.07352941176470587, '70105': 0.06372549019607843, '82758': 0.058823529411764705}\n",
      "{'62258': 0.19607843137254902, '64586': 0.12745098039215685, '58271': 0.11764705882352941, 'nlsj86871': 0.10049019607843138, '101851': 0.09558823529411764, 'nlsj183': 0.0906862745098039, '75653': 0.07598039215686274, 'nlsj59923': 0.07352941176470587, '70105': 0.06372549019607843, '82758': 0.058823529411764705}\n",
      "word id 102000 ; probability 0.035\n",
      "word id 70495 ; probability 0.035\n",
      "word id 7182 ; probability 0.029\n",
      "word id 70958 ; probability 0.024\n",
      "word id 49589 ; probability 0.021\n",
      "word id 83174 ; probability 0.021\n",
      "word id 106676 ; probability 0.019\n",
      "word id 22209 ; probability 0.018\n",
      "word id 93388 ; probability 0.017\n",
      "word id 16132 ; probability 0.016\n",
      "{'102000': 0.14893617021276598}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895, '70958': 0.1021276595744681}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895, '70958': 0.1021276595744681, '49589': 0.08936170212765958}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895, '70958': 0.1021276595744681, '49589': 0.08936170212765958, '83174': 0.08936170212765958}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895, '70958': 0.1021276595744681, '49589': 0.08936170212765958, '83174': 0.08936170212765958, '106676': 0.08085106382978724}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895, '70958': 0.1021276595744681, '49589': 0.08936170212765958, '83174': 0.08936170212765958, '106676': 0.08085106382978724, '22209': 0.07659574468085106}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895, '70958': 0.1021276595744681, '49589': 0.08936170212765958, '83174': 0.08936170212765958, '106676': 0.08085106382978724, '22209': 0.07659574468085106, '93388': 0.0723404255319149}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895, '70958': 0.1021276595744681, '49589': 0.08936170212765958, '83174': 0.08936170212765958, '106676': 0.08085106382978724, '22209': 0.07659574468085106, '93388': 0.0723404255319149, '16132': 0.06808510638297872}\n",
      "{'102000': 0.14893617021276598, '70495': 0.14893617021276598, '7182': 0.12340425531914895, '70958': 0.1021276595744681, '49589': 0.08936170212765958, '83174': 0.08936170212765958, '106676': 0.08085106382978724, '22209': 0.07659574468085106, '93388': 0.0723404255319149, '16132': 0.06808510638297872}\n",
      "word id nlsj5634 ; probability 0.039\n",
      "word id 61925 ; probability 0.037\n",
      "word id 12620 ; probability 0.030\n",
      "word id 69419 ; probability 0.027\n",
      "word id 104421 ; probability 0.027\n",
      "word id 91085 ; probability 0.024\n",
      "word id 71308 ; probability 0.022\n",
      "word id 115748 ; probability 0.021\n",
      "word id 19641 ; probability 0.020\n",
      "word id 5390 ; probability 0.019\n",
      "{'nlsj5634': 0.14661654135338348}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805, '69419': 0.10150375939849625}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805, '69419': 0.10150375939849625, '104421': 0.10150375939849625}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805, '69419': 0.10150375939849625, '104421': 0.10150375939849625, '91085': 0.09022556390977446}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805, '69419': 0.10150375939849625, '104421': 0.10150375939849625, '91085': 0.09022556390977446, '71308': 0.08270676691729324}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805, '69419': 0.10150375939849625, '104421': 0.10150375939849625, '91085': 0.09022556390977446, '71308': 0.08270676691729324, '115748': 0.07894736842105265}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805, '69419': 0.10150375939849625, '104421': 0.10150375939849625, '91085': 0.09022556390977446, '71308': 0.08270676691729324, '115748': 0.07894736842105265, '19641': 0.07518796992481204}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805, '69419': 0.10150375939849625, '104421': 0.10150375939849625, '91085': 0.09022556390977446, '71308': 0.08270676691729324, '115748': 0.07894736842105265, '19641': 0.07518796992481204, '5390': 0.07142857142857144}\n",
      "{'nlsj5634': 0.14661654135338348, '61925': 0.13909774436090228, '12620': 0.11278195488721805, '69419': 0.10150375939849625, '104421': 0.10150375939849625, '91085': 0.09022556390977446, '71308': 0.08270676691729324, '115748': 0.07894736842105265, '19641': 0.07518796992481204, '5390': 0.07142857142857144}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_output = output_senses.split(\"===============  per time  ===============\")[0].split(\"\\n\")\n",
    "\n",
    "number_of_the_k = 0\n",
    "\n",
    "k_words_with_prob = dict()\n",
    "\n",
    "for line in lines_output:\n",
    "    if line[:6] == \"p(w|s)\":\n",
    "        line = line.split(\":\")[1]\n",
    "        line = line.split(\";\")\n",
    "        #print(number_of_the_k,line)\n",
    "        dico_word_prob = dict()\n",
    "        temp_dict = dict()\n",
    "        k_words_with_prob[number_of_the_k] = list()\n",
    "        \n",
    "        line = line[:-1] # last item of the list is empty\n",
    "        \n",
    "        total_probability = 0 # to have relative probs\n",
    "        for word_prob in line:\n",
    "            \n",
    "\n",
    "        \n",
    "            #word_prob = word_prob.split(\",\")\n",
    "            #for word in word_prob:\n",
    "            probability = re.findall(\"([\\d.\\w]*)\",word_prob)\n",
    "            if probability:\n",
    "                probability = list(filter(None,probability))\n",
    "                    \n",
    "            total_probability += float(probability[1])\n",
    "            print(\"word id\",probability[0],\"; probability\",probability[1])\n",
    "        \n",
    "            dico_word_prob[probability[0]] = float(probability[1])\n",
    "        #print(type(k_words_with_prob[number_of_the_k]))\n",
    "        \n",
    "        for i in dico_word_prob.keys():\n",
    "            \n",
    "            temp_dict[i] = float(dico_word_prob[i]/total_probability)\n",
    "            k_words_with_prob[number_of_the_k] = temp_dict\n",
    "            \n",
    "            print(k_words_with_prob[number_of_the_k])\n",
    "            \n",
    "        #k_words_with_prob[number_of_the_k] = [float(dico_word_prob[i]/total_probability) for i in dico_word_prob]\n",
    "        #print(k_words_with_prob[number_of_the_k])\n",
    "        print(temp_dict)\n",
    "        number_of_the_k += 1\n",
    "        \n",
    "\n",
    "results_file.write(\"Output senses %s \\n\" %(number_of_the_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k_words_with_prob\n",
    "This dictionary has the sense number 'k' as keys and the a dictionary of [word] = probability as values.\n",
    "Example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found all\n"
     ]
    }
   ],
   "source": [
    "for word in set(list_of_all_words):\n",
    "    if word == \"105344\":\n",
    "        print(\"found all\")\n",
    "        \n",
    "for word in set(list_of_NA_words):\n",
    "    if word == \"105344\":\n",
    "        print(\"found NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#print(\"Probability for word ID 5390 in sense k = 4:\",k_words_with_prob[4][\"5390\"])\n",
    "print(type(k_words_with_prob[4]))\n",
    "\n",
    "#print(k_words_with_prob[4][\"15047\"])\n",
    "\n",
    "print(word_weight[\"105344\"])\n",
    "#print(word_weight_NA[\"105344\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output sense 0\n",
      "\texpert sense number  0 mus-1\n",
      "\t\tword from annotation for sense 0 : 28355\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  28355 is in output for sense 0 with probability: 0.2075471698113207 and weight: 1.0\n",
      "\t\tword from annotation for sense 0 : 69419\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  69419 is in output for sense 0 with probability: 0.16273584905660377 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 0 : 57460\n",
      "\t\tword from annotation for sense 0 : 114587\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  114587 is in output for sense 0 with probability: 0.0990566037735849 and weight: 1.0\n",
      "\t\tword from annotation for sense 0 : 42071\n",
      "\t\tword from annotation for sense 0 : 35267\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  35267 is in output for sense 0 with probability: 0.08254716981132075 and weight: 1.0\n",
      "\t\tword from annotation for sense 0 : 51647\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  51647 is in output for sense 0 with probability: 0.08254716981132075 and weight: 1.0\n",
      "\t\tword from annotation for sense 0 : 64448\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  64448 is in output for sense 0 with probability: 0.05424528301886792 and weight: 1.0\n",
      "\t\tword from annotation for sense 0 : 45980\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  45980 is in output for sense 0 with probability: 0.042452830188679236 and weight: 0.5\n",
      "\t\tword from annotation for sense 0 : 53826\n",
      "\texpert sense number  1 NA\n",
      "\t\tword from annotation for sense 0 : 28355\n",
      "\t\tword from annotation for sense 0 : 69419\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  69419 is in output for sense 0 with probability: 0.16273584905660377 and weight: 0.25\n",
      "\t\tword from annotation for sense 0 : 57460\n",
      "\t\tword from annotation for sense 0 : 114587\n",
      "\t\tword from annotation for sense 0 : 42071\n",
      "\t\tword from annotation for sense 0 : 35267\n",
      "\t\tword from annotation for sense 0 : 51647\n",
      "\t\tword from annotation for sense 0 : 64448\n",
      "\t\tword from annotation for sense 0 : 45980\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  45980 is in output for sense 0 with probability: 0.042452830188679236 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 0 : 53826\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  53826 is in output for sense 0 with probability: 0.04009433962264151 and weight: 1\n",
      "\texpert sense number  2 mus-4\n",
      "\t\tword from annotation for sense 0 : 28355\n",
      "\t\tword from annotation for sense 0 : 69419\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  69419 is in output for sense 0 with probability: 0.16273584905660377 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 0 : 57460\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  57460 is in output for sense 0 with probability: 0.1320754716981132 and weight: 1.0\n",
      "\t\tword from annotation for sense 0 : 114587\n",
      "\t\tword from annotation for sense 0 : 42071\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  42071 is in output for sense 0 with probability: 0.09669811320754716 and weight: 1.0\n",
      "\t\tword from annotation for sense 0 : 35267\n",
      "\t\tword from annotation for sense 0 : 51647\n",
      "\t\tword from annotation for sense 0 : 64448\n",
      "\t\tword from annotation for sense 0 : 45980\n",
      "\t\tword from annotation for sense 0 : 53826\n",
      "\texpert sense number  3 mus-2\n",
      "\t\tword from annotation for sense 0 : 28355\n",
      "\t\tword from annotation for sense 0 : 69419\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  69419 is in output for sense 0 with probability: 0.16273584905660377 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 0 : 57460\n",
      "\t\tword from annotation for sense 0 : 114587\n",
      "\t\tword from annotation for sense 0 : 42071\n",
      "\t\tword from annotation for sense 0 : 35267\n",
      "\t\tword from annotation for sense 0 : 51647\n",
      "\t\tword from annotation for sense 0 : 64448\n",
      "\t\tword from annotation for sense 0 : 45980\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  45980 is in output for sense 0 with probability: 0.042452830188679236 and weight: 0.5\n",
      "\t\tword from annotation for sense 0 : 53826\n",
      "output sense 1\n",
      "\texpert sense number  0 mus-1\n",
      "\t\tword from annotation for sense 1 : 79223\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  79223 is in output for sense 1 with probability: 0.17260273972602735 and weight: 1.0\n",
      "\t\tword from annotation for sense 1 : 92927\n",
      "\t\tword from annotation for sense 1 : 46574\n",
      "\t\tword from annotation for sense 1 : 67660\n",
      "\t\tword from annotation for sense 1 : 103085\n",
      "\t\tword from annotation for sense 1 : 86112\n",
      "\t\tword from annotation for sense 1 : 101982\n",
      "\t\tword from annotation for sense 1 : 75808\n",
      "\t\tword from annotation for sense 1 : 68539\n",
      "\t\tword from annotation for sense 1 : 54607\n",
      "\texpert sense number  1 NA\n",
      "\t\tword from annotation for sense 1 : 79223\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  79223 is in output for sense 1 with probability: 0.17260273972602735 and weight: 0.5\n",
      "\t\tword from annotation for sense 1 : 92927\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  92927 is in output for sense 1 with probability: 0.1561643835616438 and weight: 1\n",
      "\t\tword from annotation for sense 1 : 46574\n",
      "\t\tword from annotation for sense 1 : 67660\n",
      "\t\tword from annotation for sense 1 : 103085\n",
      "\t\tword from annotation for sense 1 : 86112\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  86112 is in output for sense 1 with probability: 0.08219178082191778 and weight: 1\n",
      "\t\tword from annotation for sense 1 : 101982\n",
      "\t\tword from annotation for sense 1 : 75808\n",
      "\t\tword from annotation for sense 1 : 68539\n",
      "\t\tword from annotation for sense 1 : 54607\n",
      "\texpert sense number  2 mus-4\n",
      "\t\tword from annotation for sense 1 : 79223\n",
      "\t\tword from annotation for sense 1 : 92927\n",
      "\t\tword from annotation for sense 1 : 46574\n",
      "\t\tword from annotation for sense 1 : 67660\n",
      "\t\tword from annotation for sense 1 : 103085\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  103085 is in output for sense 1 with probability: 0.09863013698630134 and weight: 1.0\n",
      "\t\tword from annotation for sense 1 : 86112\n",
      "\t\tword from annotation for sense 1 : 101982\n",
      "\t\tword from annotation for sense 1 : 75808\n",
      "\t\tword from annotation for sense 1 : 68539\n",
      "\t\tword from annotation for sense 1 : 54607\n",
      "\texpert sense number  3 mus-2\n",
      "\t\tword from annotation for sense 1 : 79223\n",
      "\t\tword from annotation for sense 1 : 92927\n",
      "\t\tword from annotation for sense 1 : 46574\n",
      "\t\tword from annotation for sense 1 : 67660\n",
      "\t\tword from annotation for sense 1 : 103085\n",
      "\t\tword from annotation for sense 1 : 86112\n",
      "\t\tword from annotation for sense 1 : 101982\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  101982 is in output for sense 1 with probability: 0.07945205479452053 and weight: 1.0\n",
      "\t\tword from annotation for sense 1 : 75808\n",
      "\t\tword from annotation for sense 1 : 68539\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  68539 is in output for sense 1 with probability: 0.06575342465753423 and weight: 1.0\n",
      "\t\tword from annotation for sense 1 : 54607\n",
      "output sense 2\n",
      "\texpert sense number  0 mus-1\n",
      "\t\tword from annotation for sense 2 : 62258\n",
      "\t\tword from annotation for sense 2 : 64586\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  64586 is in output for sense 2 with probability: 0.12745098039215685 and weight: 1.0\n",
      "\t\tword from annotation for sense 2 : 58271\n",
      "\t\tword from annotation for sense 2 : nlsj86871\n",
      "\t\tword from annotation for sense 2 : 101851\n",
      "\t\tword from annotation for sense 2 : nlsj183\n",
      "\t\tword from annotation for sense 2 : 75653\n",
      "\t\tword from annotation for sense 2 : nlsj59923\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  nlsj59923 is in output for sense 2 with probability: 0.07352941176470587 and weight: 1.0\n",
      "\t\tword from annotation for sense 2 : 70105\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  70105 is in output for sense 2 with probability: 0.06372549019607843 and weight: 1.0\n",
      "\t\tword from annotation for sense 2 : 82758\n",
      "\texpert sense number  1 NA\n",
      "\t\tword from annotation for sense 2 : 62258\n",
      "\t\tword from annotation for sense 2 : 64586\n",
      "\t\tword from annotation for sense 2 : 58271\n",
      "\t\tword from annotation for sense 2 : nlsj86871\n",
      "\t\tword from annotation for sense 2 : 101851\n",
      "\t\tword from annotation for sense 2 : nlsj183\n",
      "\t\tword from annotation for sense 2 : 75653\n",
      "\t\tword from annotation for sense 2 : nlsj59923\n",
      "\t\tword from annotation for sense 2 : 70105\n",
      "\t\tword from annotation for sense 2 : 82758\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  82758 is in output for sense 2 with probability: 0.058823529411764705 and weight: 0.5\n",
      "\texpert sense number  2 mus-4\n",
      "\t\tword from annotation for sense 2 : 62258\n",
      "\t\tword from annotation for sense 2 : 64586\n",
      "\t\tword from annotation for sense 2 : 58271\n",
      "\t\tword from annotation for sense 2 : nlsj86871\n",
      "\t\tword from annotation for sense 2 : 101851\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  101851 is in output for sense 2 with probability: 0.09558823529411764 and weight: 1.0\n",
      "\t\tword from annotation for sense 2 : nlsj183\n",
      "\t\tword from annotation for sense 2 : 75653\n",
      "\t\tword from annotation for sense 2 : nlsj59923\n",
      "\t\tword from annotation for sense 2 : 70105\n",
      "\t\tword from annotation for sense 2 : 82758\n",
      "\texpert sense number  3 mus-2\n",
      "\t\tword from annotation for sense 2 : 62258\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  62258 is in output for sense 2 with probability: 0.19607843137254902 and weight: 1.0\n",
      "\t\tword from annotation for sense 2 : 64586\n",
      "\t\tword from annotation for sense 2 : 58271\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  58271 is in output for sense 2 with probability: 0.11764705882352941 and weight: 1.0\n",
      "\t\tword from annotation for sense 2 : nlsj86871\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  nlsj86871 is in output for sense 2 with probability: 0.10049019607843138 and weight: 1.0\n",
      "\t\tword from annotation for sense 2 : 101851\n",
      "\t\tword from annotation for sense 2 : nlsj183\n",
      "\t\tword from annotation for sense 2 : 75653\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  75653 is in output for sense 2 with probability: 0.07598039215686274 and weight: 1.0\n",
      "\t\tword from annotation for sense 2 : nlsj59923\n",
      "\t\tword from annotation for sense 2 : 70105\n",
      "\t\tword from annotation for sense 2 : 82758\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  82758 is in output for sense 2 with probability: 0.058823529411764705 and weight: 1.0\n",
      "output sense 3\n",
      "\texpert sense number  0 mus-1\n",
      "\t\tword from annotation for sense 3 : 102000\n",
      "\t\tword from annotation for sense 3 : 70495\n",
      "\t\tword from annotation for sense 3 : 7182\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  7182 is in output for sense 3 with probability: 0.12340425531914895 and weight: 1.0\n",
      "\t\tword from annotation for sense 3 : 70958\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  70958 is in output for sense 3 with probability: 0.1021276595744681 and weight: 1.0\n",
      "\t\tword from annotation for sense 3 : 49589\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  49589 is in output for sense 3 with probability: 0.08936170212765958 and weight: 1.0\n",
      "\t\tword from annotation for sense 3 : 83174\n",
      "\t\tword from annotation for sense 3 : 106676\n",
      "\t\tword from annotation for sense 3 : 22209\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  22209 is in output for sense 3 with probability: 0.07659574468085106 and weight: 0.5\n",
      "\t\tword from annotation for sense 3 : 93388\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  93388 is in output for sense 3 with probability: 0.0723404255319149 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 3 : 16132\n",
      "\texpert sense number  1 NA\n",
      "\t\tword from annotation for sense 3 : 102000\n",
      "\t\tword from annotation for sense 3 : 70495\n",
      "\t\tword from annotation for sense 3 : 7182\n",
      "\t\tword from annotation for sense 3 : 70958\n",
      "\t\tword from annotation for sense 3 : 49589\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  49589 is in output for sense 3 with probability: 0.08936170212765958 and weight: 0.5\n",
      "\t\tword from annotation for sense 3 : 83174\n",
      "\t\tword from annotation for sense 3 : 106676\n",
      "\t\tword from annotation for sense 3 : 22209\n",
      "\t\tword from annotation for sense 3 : 93388\n",
      "\t\tword from annotation for sense 3 : 16132\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  16132 is in output for sense 3 with probability: 0.06808510638297872 and weight: 1\n",
      "\texpert sense number  2 mus-4\n",
      "\t\tword from annotation for sense 3 : 102000\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  102000 is in output for sense 3 with probability: 0.14893617021276598 and weight: 1.0\n",
      "\t\tword from annotation for sense 3 : 70495\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  70495 is in output for sense 3 with probability: 0.14893617021276598 and weight: 1.0\n",
      "\t\tword from annotation for sense 3 : 7182\n",
      "\t\tword from annotation for sense 3 : 70958\n",
      "\t\tword from annotation for sense 3 : 49589\n",
      "\t\tword from annotation for sense 3 : 83174\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  83174 is in output for sense 3 with probability: 0.08936170212765958 and weight: 1.0\n",
      "\t\tword from annotation for sense 3 : 106676\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  106676 is in output for sense 3 with probability: 0.08085106382978724 and weight: 1.0\n",
      "\t\tword from annotation for sense 3 : 22209\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  22209 is in output for sense 3 with probability: 0.07659574468085106 and weight: 0.5\n",
      "\t\tword from annotation for sense 3 : 93388\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  93388 is in output for sense 3 with probability: 0.0723404255319149 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 3 : 16132\n",
      "\texpert sense number  3 mus-2\n",
      "\t\tword from annotation for sense 3 : 102000\n",
      "\t\tword from annotation for sense 3 : 70495\n",
      "\t\tword from annotation for sense 3 : 7182\n",
      "\t\tword from annotation for sense 3 : 70958\n",
      "\t\tword from annotation for sense 3 : 49589\n",
      "\t\tword from annotation for sense 3 : 83174\n",
      "\t\tword from annotation for sense 3 : 106676\n",
      "\t\tword from annotation for sense 3 : 22209\n",
      "\t\tword from annotation for sense 3 : 93388\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  93388 is in output for sense 3 with probability: 0.0723404255319149 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 3 : 16132\n",
      "output sense 4\n",
      "\texpert sense number  0 mus-1\n",
      "\t\tword from annotation for sense 4 : nlsj5634\n",
      "\t\tword from annotation for sense 4 : 61925\n",
      "\t\tword from annotation for sense 4 : 12620\n",
      "\t\tword from annotation for sense 4 : 69419\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  69419 is in output for sense 4 with probability: 0.10150375939849625 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 4 : 104421\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  104421 is in output for sense 4 with probability: 0.10150375939849625 and weight: 1.0\n",
      "\t\tword from annotation for sense 4 : 91085\n",
      "\t\tword from annotation for sense 4 : 71308\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  71308 is in output for sense 4 with probability: 0.08270676691729324 and weight: 1.0\n",
      "\t\tword from annotation for sense 4 : 115748\n",
      "\t\tword from annotation for sense 4 : 19641\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  19641 is in output for sense 4 with probability: 0.07518796992481204 and weight: 1.0\n",
      "\t\tword from annotation for sense 4 : 5390\n",
      "\texpert sense number  1 NA\n",
      "\t\tword from annotation for sense 4 : nlsj5634\n",
      "\t\tword from annotation for sense 4 : 61925\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  61925 is in output for sense 4 with probability: 0.13909774436090228 and weight: 1\n",
      "\t\tword from annotation for sense 4 : 12620\n",
      "\t\tword from annotation for sense 4 : 69419\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  69419 is in output for sense 4 with probability: 0.10150375939849625 and weight: 0.25\n",
      "\t\tword from annotation for sense 4 : 104421\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  104421 is in output for sense 4 with probability: 0.10150375939849625 and weight: 0.5\n",
      "\t\tword from annotation for sense 4 : 91085\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  91085 is in output for sense 4 with probability: 0.09022556390977446 and weight: 1\n",
      "\t\tword from annotation for sense 4 : 71308\n",
      "\t\tword from annotation for sense 4 : 115748\n",
      "\t\tword from annotation for sense 4 : 19641\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  19641 is in output for sense 4 with probability: 0.07518796992481204 and weight: 0.5\n",
      "\t\tword from annotation for sense 4 : 5390\n",
      "\t\t\t\tNA\n",
      "\t\t\tword  5390 is in output for sense 4 with probability: 0.07142857142857144 and weight: 1\n",
      "\texpert sense number  2 mus-4\n",
      "\t\tword from annotation for sense 4 : nlsj5634\n",
      "\t\tword from annotation for sense 4 : 61925\n",
      "\t\tword from annotation for sense 4 : 12620\n",
      "\t\tword from annotation for sense 4 : 69419\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  69419 is in output for sense 4 with probability: 0.10150375939849625 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 4 : 104421\n",
      "\t\tword from annotation for sense 4 : 91085\n",
      "\t\tword from annotation for sense 4 : 71308\n",
      "\t\tword from annotation for sense 4 : 115748\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  115748 is in output for sense 4 with probability: 0.07894736842105265 and weight: 1.0\n",
      "\t\tword from annotation for sense 4 : 19641\n",
      "\t\tword from annotation for sense 4 : 5390\n",
      "\texpert sense number  3 mus-2\n",
      "\t\tword from annotation for sense 4 : nlsj5634\n",
      "\t\tword from annotation for sense 4 : 61925\n",
      "\t\tword from annotation for sense 4 : 12620\n",
      "\t\tword from annotation for sense 4 : 69419\n",
      "\t\t\t\tnormal\n",
      "\t\t\tword  69419 is in output for sense 4 with probability: 0.10150375939849625 and weight: 0.3333333333333333\n",
      "\t\tword from annotation for sense 4 : 104421\n",
      "\t\tword from annotation for sense 4 : 91085\n",
      "\t\tword from annotation for sense 4 : 71308\n",
      "\t\tword from annotation for sense 4 : 115748\n",
      "\t\tword from annotation for sense 4 : 19641\n",
      "\t\tword from annotation for sense 4 : 5390\n"
     ]
    }
   ],
   "source": [
    "for key in k_words_with_prob.keys():\n",
    "    print(\"output sense\",key)\n",
    "    for i in range(0,number_of_s):\n",
    "        print(\"\\texpert sense number \", i, expert_senses[i])\n",
    "        for second_key in k_words_with_prob[key].keys(): # Barbara's note: shouldn't it be k_words_with_prob[i] here?\n",
    "            print(\"\\t\\tword from annotation for sense\", key, \":\", second_key)\n",
    "            if second_key in dict_of_words[expert_senses[i]]:\n",
    "                if expert_senses[i] != \"NA\":\n",
    "                    print(\"\\t\\t\\t\\tnormal\")\n",
    "                    print(\"\\t\\t\\tword \", second_key, \"is in output for sense\", key, \"with probability:\", k_words_with_prob[key][second_key], \"and weight:\", word_weight[second_key])\n",
    "\n",
    "                else:\n",
    "                    print(\"\\t\\t\\t\\tNA\")\n",
    "                    print(\"\\t\\t\\tword \", second_key, \"is in output for sense\", key, \"with probability:\", k_words_with_prob[key][second_key], \"and weight:\", word_weight_NA[second_key])\n",
    "\n",
    "                \n",
    "# Here we get all the senses and for each sense we do a matching between the k words and s words and get the probability\n",
    "# For some reason the first word for each sense arrives several times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of expert senses s: 4\n",
      "number of model output senses k: 5\n",
      "\n",
      "\n",
      "Choose best match for k = 0\n",
      "k,mot 0 28355\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.2075471698113207\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 28355 match_weighted 0.2075471698113207\n",
      "k,mot 0 69419\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.16273584905660377\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-1 mot 69419 match_weighted 0.05424528301886792\n",
      "k,mot 0 57460\n",
      "expert_senses[s] mus-1\n",
      "k,mot 0 114587\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.0990566037735849\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 114587 match_weighted 0.0990566037735849\n",
      "k,mot 0 42071\n",
      "expert_senses[s] mus-1\n",
      "k,mot 0 35267\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.08254716981132075\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 35267 match_weighted 0.08254716981132075\n",
      "k,mot 0 51647\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.08254716981132075\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 51647 match_weighted 0.08254716981132075\n",
      "k,mot 0 64448\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.05424528301886792\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 64448 match_weighted 0.05424528301886792\n",
      "k,mot 0 45980\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.042452830188679236\n",
      "word_weight[mot] 0.5\n",
      "sense mus-1 mot 45980 match_weighted 0.021226415094339618\n",
      "k,mot 0 53826\n",
      "expert_senses[s] mus-1\n",
      "k,mot 0 28355\n",
      "expert_senses[s] NA\n",
      "k,mot 0 69419\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.16273584905660377\n",
      "word_weight[mot] 0.25\n",
      "sense NA mot 69419 match_weighted 0.04068396226415094\n",
      "k,mot 0 57460\n",
      "expert_senses[s] NA\n",
      "k,mot 0 114587\n",
      "expert_senses[s] NA\n",
      "k,mot 0 42071\n",
      "expert_senses[s] NA\n",
      "k,mot 0 35267\n",
      "expert_senses[s] NA\n",
      "k,mot 0 51647\n",
      "expert_senses[s] NA\n",
      "k,mot 0 64448\n",
      "expert_senses[s] NA\n",
      "k,mot 0 45980\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.042452830188679236\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense NA mot 45980 match_weighted 0.014150943396226412\n",
      "k,mot 0 53826\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.04009433962264151\n",
      "word_weight[mot] 1\n",
      "sense NA mot 53826 match_weighted 0.04009433962264151\n",
      "k,mot 0 28355\n",
      "expert_senses[s] mus-4\n",
      "k,mot 0 69419\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.16273584905660377\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-4 mot 69419 match_weighted 0.05424528301886792\n",
      "k,mot 0 57460\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.1320754716981132\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 57460 match_weighted 0.1320754716981132\n",
      "k,mot 0 114587\n",
      "expert_senses[s] mus-4\n",
      "k,mot 0 42071\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.09669811320754716\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 42071 match_weighted 0.09669811320754716\n",
      "k,mot 0 35267\n",
      "expert_senses[s] mus-4\n",
      "k,mot 0 51647\n",
      "expert_senses[s] mus-4\n",
      "k,mot 0 64448\n",
      "expert_senses[s] mus-4\n",
      "k,mot 0 45980\n",
      "expert_senses[s] mus-4\n",
      "k,mot 0 53826\n",
      "expert_senses[s] mus-4\n",
      "k,mot 0 28355\n",
      "expert_senses[s] mus-2\n",
      "k,mot 0 69419\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.16273584905660377\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-2 mot 69419 match_weighted 0.05424528301886792\n",
      "k,mot 0 57460\n",
      "expert_senses[s] mus-2\n",
      "k,mot 0 114587\n",
      "expert_senses[s] mus-2\n",
      "k,mot 0 42071\n",
      "expert_senses[s] mus-2\n",
      "k,mot 0 35267\n",
      "expert_senses[s] mus-2\n",
      "k,mot 0 51647\n",
      "expert_senses[s] mus-2\n",
      "k,mot 0 64448\n",
      "expert_senses[s] mus-2\n",
      "k,mot 0 45980\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.042452830188679236\n",
      "word_weight[mot] 0.5\n",
      "sense mus-2 mot 45980 match_weighted 0.021226415094339618\n",
      "k,mot 0 53826\n",
      "expert_senses[s] mus-2\n",
      "\n",
      "\n",
      "Choose best match for k = 1\n",
      "k,mot 1 79223\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.17260273972602735\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 79223 match_weighted 0.17260273972602735\n",
      "k,mot 1 92927\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 46574\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 67660\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 103085\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 86112\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 101982\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 75808\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 68539\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 54607\n",
      "expert_senses[s] mus-1\n",
      "k,mot 1 79223\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.17260273972602735\n",
      "word_weight[mot] 0.5\n",
      "sense NA mot 79223 match_weighted 0.08630136986301368\n",
      "k,mot 1 92927\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.1561643835616438\n",
      "word_weight[mot] 1\n",
      "sense NA mot 92927 match_weighted 0.1561643835616438\n",
      "k,mot 1 46574\n",
      "expert_senses[s] NA\n",
      "k,mot 1 67660\n",
      "expert_senses[s] NA\n",
      "k,mot 1 103085\n",
      "expert_senses[s] NA\n",
      "k,mot 1 86112\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.08219178082191778\n",
      "word_weight[mot] 1\n",
      "sense NA mot 86112 match_weighted 0.08219178082191778\n",
      "k,mot 1 101982\n",
      "expert_senses[s] NA\n",
      "k,mot 1 75808\n",
      "expert_senses[s] NA\n",
      "k,mot 1 68539\n",
      "expert_senses[s] NA\n",
      "k,mot 1 54607\n",
      "expert_senses[s] NA\n",
      "k,mot 1 79223\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 92927\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 46574\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 67660\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 103085\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.09863013698630134\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 103085 match_weighted 0.09863013698630134\n",
      "k,mot 1 86112\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 101982\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 75808\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 68539\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 54607\n",
      "expert_senses[s] mus-4\n",
      "k,mot 1 79223\n",
      "expert_senses[s] mus-2\n",
      "k,mot 1 92927\n",
      "expert_senses[s] mus-2\n",
      "k,mot 1 46574\n",
      "expert_senses[s] mus-2\n",
      "k,mot 1 67660\n",
      "expert_senses[s] mus-2\n",
      "k,mot 1 103085\n",
      "expert_senses[s] mus-2\n",
      "k,mot 1 86112\n",
      "expert_senses[s] mus-2\n",
      "k,mot 1 101982\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.07945205479452053\n",
      "word_weight[mot] 1.0\n",
      "sense mus-2 mot 101982 match_weighted 0.07945205479452053\n",
      "k,mot 1 75808\n",
      "expert_senses[s] mus-2\n",
      "k,mot 1 68539\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.06575342465753423\n",
      "word_weight[mot] 1.0\n",
      "sense mus-2 mot 68539 match_weighted 0.06575342465753423\n",
      "k,mot 1 54607\n",
      "expert_senses[s] mus-2\n",
      "\n",
      "\n",
      "Choose best match for k = 2\n",
      "k,mot 2 62258\n",
      "expert_senses[s] mus-1\n",
      "k,mot 2 64586\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.12745098039215685\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 64586 match_weighted 0.12745098039215685\n",
      "k,mot 2 58271\n",
      "expert_senses[s] mus-1\n",
      "k,mot 2 nlsj86871\n",
      "expert_senses[s] mus-1\n",
      "k,mot 2 101851\n",
      "expert_senses[s] mus-1\n",
      "k,mot 2 nlsj183\n",
      "expert_senses[s] mus-1\n",
      "k,mot 2 75653\n",
      "expert_senses[s] mus-1\n",
      "k,mot 2 nlsj59923\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.07352941176470587\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot nlsj59923 match_weighted 0.07352941176470587\n",
      "k,mot 2 70105\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.06372549019607843\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 70105 match_weighted 0.06372549019607843\n",
      "k,mot 2 82758\n",
      "expert_senses[s] mus-1\n",
      "k,mot 2 62258\n",
      "expert_senses[s] NA\n",
      "k,mot 2 64586\n",
      "expert_senses[s] NA\n",
      "k,mot 2 58271\n",
      "expert_senses[s] NA\n",
      "k,mot 2 nlsj86871\n",
      "expert_senses[s] NA\n",
      "k,mot 2 101851\n",
      "expert_senses[s] NA\n",
      "k,mot 2 nlsj183\n",
      "expert_senses[s] NA\n",
      "k,mot 2 75653\n",
      "expert_senses[s] NA\n",
      "k,mot 2 nlsj59923\n",
      "expert_senses[s] NA\n",
      "k,mot 2 70105\n",
      "expert_senses[s] NA\n",
      "k,mot 2 82758\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.058823529411764705\n",
      "word_weight[mot] 0.5\n",
      "sense NA mot 82758 match_weighted 0.029411764705882353\n",
      "k,mot 2 62258\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 64586\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 58271\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 nlsj86871\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 101851\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.09558823529411764\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 101851 match_weighted 0.09558823529411764\n",
      "k,mot 2 nlsj183\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 75653\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 nlsj59923\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 70105\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 82758\n",
      "expert_senses[s] mus-4\n",
      "k,mot 2 62258\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.19607843137254902\n",
      "word_weight[mot] 1.0\n",
      "sense mus-2 mot 62258 match_weighted 0.19607843137254902\n",
      "k,mot 2 64586\n",
      "expert_senses[s] mus-2\n",
      "k,mot 2 58271\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.11764705882352941\n",
      "word_weight[mot] 1.0\n",
      "sense mus-2 mot 58271 match_weighted 0.11764705882352941\n",
      "k,mot 2 nlsj86871\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.10049019607843138\n",
      "word_weight[mot] 1.0\n",
      "sense mus-2 mot nlsj86871 match_weighted 0.10049019607843138\n",
      "k,mot 2 101851\n",
      "expert_senses[s] mus-2\n",
      "k,mot 2 nlsj183\n",
      "expert_senses[s] mus-2\n",
      "k,mot 2 75653\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.07598039215686274\n",
      "word_weight[mot] 1.0\n",
      "sense mus-2 mot 75653 match_weighted 0.07598039215686274\n",
      "k,mot 2 nlsj59923\n",
      "expert_senses[s] mus-2\n",
      "k,mot 2 70105\n",
      "expert_senses[s] mus-2\n",
      "k,mot 2 82758\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.058823529411764705\n",
      "word_weight[mot] 1.0\n",
      "sense mus-2 mot 82758 match_weighted 0.058823529411764705\n",
      "\n",
      "\n",
      "Choose best match for k = 3\n",
      "k,mot 3 102000\n",
      "expert_senses[s] mus-1\n",
      "k,mot 3 70495\n",
      "expert_senses[s] mus-1\n",
      "k,mot 3 7182\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.12340425531914895\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 7182 match_weighted 0.12340425531914895\n",
      "k,mot 3 70958\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.1021276595744681\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 70958 match_weighted 0.1021276595744681\n",
      "k,mot 3 49589\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.08936170212765958\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 49589 match_weighted 0.08936170212765958\n",
      "k,mot 3 83174\n",
      "expert_senses[s] mus-1\n",
      "k,mot 3 106676\n",
      "expert_senses[s] mus-1\n",
      "k,mot 3 22209\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.07659574468085106\n",
      "word_weight[mot] 0.5\n",
      "sense mus-1 mot 22209 match_weighted 0.03829787234042553\n",
      "k,mot 3 93388\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.0723404255319149\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-1 mot 93388 match_weighted 0.024113475177304965\n",
      "k,mot 3 16132\n",
      "expert_senses[s] mus-1\n",
      "k,mot 3 102000\n",
      "expert_senses[s] NA\n",
      "k,mot 3 70495\n",
      "expert_senses[s] NA\n",
      "k,mot 3 7182\n",
      "expert_senses[s] NA\n",
      "k,mot 3 70958\n",
      "expert_senses[s] NA\n",
      "k,mot 3 49589\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.08936170212765958\n",
      "word_weight[mot] 0.5\n",
      "sense NA mot 49589 match_weighted 0.04468085106382979\n",
      "k,mot 3 83174\n",
      "expert_senses[s] NA\n",
      "k,mot 3 106676\n",
      "expert_senses[s] NA\n",
      "k,mot 3 22209\n",
      "expert_senses[s] NA\n",
      "k,mot 3 93388\n",
      "expert_senses[s] NA\n",
      "k,mot 3 16132\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.06808510638297872\n",
      "word_weight[mot] 1\n",
      "sense NA mot 16132 match_weighted 0.06808510638297872\n",
      "k,mot 3 102000\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.14893617021276598\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 102000 match_weighted 0.14893617021276598\n",
      "k,mot 3 70495\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.14893617021276598\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 70495 match_weighted 0.14893617021276598\n",
      "k,mot 3 7182\n",
      "expert_senses[s] mus-4\n",
      "k,mot 3 70958\n",
      "expert_senses[s] mus-4\n",
      "k,mot 3 49589\n",
      "expert_senses[s] mus-4\n",
      "k,mot 3 83174\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.08936170212765958\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 83174 match_weighted 0.08936170212765958\n",
      "k,mot 3 106676\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.08085106382978724\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 106676 match_weighted 0.08085106382978724\n",
      "k,mot 3 22209\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.07659574468085106\n",
      "word_weight[mot] 0.5\n",
      "sense mus-4 mot 22209 match_weighted 0.03829787234042553\n",
      "k,mot 3 93388\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.0723404255319149\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-4 mot 93388 match_weighted 0.024113475177304965\n",
      "k,mot 3 16132\n",
      "expert_senses[s] mus-4\n",
      "k,mot 3 102000\n",
      "expert_senses[s] mus-2\n",
      "k,mot 3 70495\n",
      "expert_senses[s] mus-2\n",
      "k,mot 3 7182\n",
      "expert_senses[s] mus-2\n",
      "k,mot 3 70958\n",
      "expert_senses[s] mus-2\n",
      "k,mot 3 49589\n",
      "expert_senses[s] mus-2\n",
      "k,mot 3 83174\n",
      "expert_senses[s] mus-2\n",
      "k,mot 3 106676\n",
      "expert_senses[s] mus-2\n",
      "k,mot 3 22209\n",
      "expert_senses[s] mus-2\n",
      "k,mot 3 93388\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.0723404255319149\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-2 mot 93388 match_weighted 0.024113475177304965\n",
      "k,mot 3 16132\n",
      "expert_senses[s] mus-2\n",
      "\n",
      "\n",
      "Choose best match for k = 4\n",
      "k,mot 4 nlsj5634\n",
      "expert_senses[s] mus-1\n",
      "k,mot 4 61925\n",
      "expert_senses[s] mus-1\n",
      "k,mot 4 12620\n",
      "expert_senses[s] mus-1\n",
      "k,mot 4 69419\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.10150375939849625\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-1 mot 69419 match_weighted 0.03383458646616541\n",
      "k,mot 4 104421\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.10150375939849625\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 104421 match_weighted 0.10150375939849625\n",
      "k,mot 4 91085\n",
      "expert_senses[s] mus-1\n",
      "k,mot 4 71308\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.08270676691729324\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 71308 match_weighted 0.08270676691729324\n",
      "k,mot 4 115748\n",
      "expert_senses[s] mus-1\n",
      "k,mot 4 19641\n",
      "expert_senses[s] mus-1\n",
      "k_words_with_prob[k][mot] 0.07518796992481204\n",
      "word_weight[mot] 1.0\n",
      "sense mus-1 mot 19641 match_weighted 0.07518796992481204\n",
      "k,mot 4 5390\n",
      "expert_senses[s] mus-1\n",
      "k,mot 4 nlsj5634\n",
      "expert_senses[s] NA\n",
      "k,mot 4 61925\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.13909774436090228\n",
      "word_weight[mot] 1\n",
      "sense NA mot 61925 match_weighted 0.13909774436090228\n",
      "k,mot 4 12620\n",
      "expert_senses[s] NA\n",
      "k,mot 4 69419\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.10150375939849625\n",
      "word_weight[mot] 0.25\n",
      "sense NA mot 69419 match_weighted 0.025375939849624062\n",
      "k,mot 4 104421\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.10150375939849625\n",
      "word_weight[mot] 0.5\n",
      "sense NA mot 104421 match_weighted 0.050751879699248124\n",
      "k,mot 4 91085\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.09022556390977446\n",
      "word_weight[mot] 1\n",
      "sense NA mot 91085 match_weighted 0.09022556390977446\n",
      "k,mot 4 71308\n",
      "expert_senses[s] NA\n",
      "k,mot 4 115748\n",
      "expert_senses[s] NA\n",
      "k,mot 4 19641\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.07518796992481204\n",
      "word_weight[mot] 0.5\n",
      "sense NA mot 19641 match_weighted 0.03759398496240602\n",
      "k,mot 4 5390\n",
      "expert_senses[s] NA\n",
      "k_words_with_prob[k][mot] 0.07142857142857144\n",
      "word_weight[mot] 1\n",
      "sense NA mot 5390 match_weighted 0.07142857142857144\n",
      "k,mot 4 nlsj5634\n",
      "expert_senses[s] mus-4\n",
      "k,mot 4 61925\n",
      "expert_senses[s] mus-4\n",
      "k,mot 4 12620\n",
      "expert_senses[s] mus-4\n",
      "k,mot 4 69419\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.10150375939849625\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-4 mot 69419 match_weighted 0.03383458646616541\n",
      "k,mot 4 104421\n",
      "expert_senses[s] mus-4\n",
      "k,mot 4 91085\n",
      "expert_senses[s] mus-4\n",
      "k,mot 4 71308\n",
      "expert_senses[s] mus-4\n",
      "k,mot 4 115748\n",
      "expert_senses[s] mus-4\n",
      "k_words_with_prob[k][mot] 0.07894736842105265\n",
      "word_weight[mot] 1.0\n",
      "sense mus-4 mot 115748 match_weighted 0.07894736842105265\n",
      "k,mot 4 19641\n",
      "expert_senses[s] mus-4\n",
      "k,mot 4 5390\n",
      "expert_senses[s] mus-4\n",
      "k,mot 4 nlsj5634\n",
      "expert_senses[s] mus-2\n",
      "k,mot 4 61925\n",
      "expert_senses[s] mus-2\n",
      "k,mot 4 12620\n",
      "expert_senses[s] mus-2\n",
      "k,mot 4 69419\n",
      "expert_senses[s] mus-2\n",
      "k_words_with_prob[k][mot] 0.10150375939849625\n",
      "word_weight[mot] 0.3333333333333333\n",
      "sense mus-2 mot 69419 match_weighted 0.03383458646616541\n",
      "k,mot 4 104421\n",
      "expert_senses[s] mus-2\n",
      "k,mot 4 91085\n",
      "expert_senses[s] mus-2\n",
      "k,mot 4 71308\n",
      "expert_senses[s] mus-2\n",
      "k,mot 4 115748\n",
      "expert_senses[s] mus-2\n",
      "k,mot 4 19641\n",
      "expert_senses[s] mus-2\n",
      "k,mot 4 5390\n",
      "expert_senses[s] mus-2\n"
     ]
    }
   ],
   "source": [
    "## Calculating confidence score for each (words_of_k,words_of_s) pair\n",
    "\n",
    "# conf(k,s) = (p1*match(w1,s)+p2*match(w1,s)+px(wx,s))\n",
    "        # match(wx,s) =   1/number_of_senses_assigned_to_wx if s_is_one_of_them \n",
    "\n",
    "    \n",
    "print(\"number of expert senses s:\",number_of_s)\n",
    "print(\"number of model output senses k:\",len(k_words_with_prob.keys()))\n",
    "compteur = 0\n",
    "\n",
    "match = dict()\n",
    "conf = dict()\n",
    "for k in k_words_with_prob.keys():  # for each output sense, we go through...\n",
    "    print(\"\\n\")\n",
    "    print(\"Choose best match for k =\",k)\n",
    "    for s in range(0,number_of_s):       # each expert sense\n",
    "        \n",
    "        conf[k,s] = 0 \n",
    "        \n",
    "        #print(\"expert sense\",s)\n",
    "        for mot in k_words_with_prob[k]:      # for each word within output by the model for the output sense\n",
    "            print(\"k,mot\",k,mot)\n",
    "            print(\"expert_senses[s]\",expert_senses[s])\n",
    "            \n",
    "            if expert_senses[s] == \"NA\":\n",
    "                \n",
    "                if mot in dict_of_words[expert_senses[s]]:  # if that word exists in the list of expert words for that sense\n",
    "\n",
    "                    #print(\"s,dict_of_words[expert_senses[s]])\",dict_of_words[expert_senses[s]])\n",
    "                    print(\"k_words_with_prob[k][mot]\",k_words_with_prob[k][mot])\n",
    "                    print(\"word_weight[mot]\",word_weight_NA[mot])\n",
    "\n",
    "                    #for word in list_of_all_words:  # this help getting a key for a dictionary later on\n",
    "                     #   if mot == word:\n",
    "                    match_weighted = float((k_words_with_prob[k][mot]))*word_weight_NA[mot] #this dictionary cfr comment on line 24\n",
    "                            # word_weight[word] is already \"1/number_of_expert_senses_assigned_to_this_word\"\n",
    "\n",
    "                    print(\"sense\",expert_senses[s],\"mot\",mot,\"match_weighted\",match_weighted)\n",
    "\n",
    "                            #print(k,s,conf[k,s])\n",
    "\n",
    "\n",
    "                            # To fix? \n",
    "                            # The way the code works is that all matches happen number_of_s times\n",
    "                            # (number_of_s = number of expert senses)\n",
    "                            # easy fix is to divide the match score by number_of_s\n",
    "\n",
    "                    conf[k,s] = conf[k,s] + match_weighted#/4\n",
    "\n",
    "                \n",
    "                \n",
    "            else:    \n",
    " \n",
    "                if mot in dict_of_words[expert_senses[s]]:  # if that word exists in the list of expert words for that sense\n",
    "\n",
    "                    #print(\"s,dict_of_words[expert_senses[s]])\",dict_of_words[expert_senses[s]])\n",
    "                    print(\"k_words_with_prob[k][mot]\",k_words_with_prob[k][mot])\n",
    "                    print(\"word_weight[mot]\",word_weight[mot])\n",
    "\n",
    "                    #for word in list_of_all_words:  # this help getting a key for a dictionary later on\n",
    "                     #   if mot == word:\n",
    "                    match_weighted = float((k_words_with_prob[k][mot]))*word_weight[mot] #this dictionary cfr comment on line 24\n",
    "                            # word_weight[word] is already \"1/number_of_expert_senses_assigned_to_this_word\"\n",
    "\n",
    "                    print(\"sense\",expert_senses[s],\"mot\",mot,\"match_weighted\",match_weighted)\n",
    "\n",
    "                            #print(k,s,conf[k,s])\n",
    "\n",
    "\n",
    "                            # To fix? \n",
    "                            # The way the code works is that all matches happen number_of_s times\n",
    "                            # (number_of_s = number of expert senses)\n",
    "                            # easy fix is to divide the match score by number_of_s\n",
    "\n",
    "                    conf[k,s] = conf[k,s] + match_weighted#/4\n",
    "\n",
    "                    #else: \n",
    "                        #print(word,\"has no match for sense\",expert_senses[s])\n",
    "                        #print(word,word_weight[word],\"match\",k_words_with_prob[k][mot],\"match weighted\",match_weighted)\n",
    "                    #print(\"test1\")\n",
    "                #print(\"test2\")\n",
    "                \n",
    "                    #compteur += 1\n",
    "                \n",
    "        #if (k,s) in conf.keys():\n",
    "        \n",
    "            #conf[k,s] = conf[k,s] # with or without /10\n",
    "            #print(\"k =\",k,\"\\t s =\",s,\"(= expert sense\",expert_senses[s],\")\\t conf[k,s] =\",conf[k,s])\n",
    "            \n",
    "            #print(compteur)\n",
    "            \n",
    "    #print(k_words_with_prob[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 0.6014150943396226, (0, 1): 0.09492924528301885, (0, 2): 0.2830188679245283, (0, 3): 0.07547169811320753, (1, 0): 0.17260273972602735, (1, 1): 0.3246575342465753, (1, 2): 0.09863013698630134, (1, 3): 0.14520547945205475, (2, 0): 0.2647058823529411, (2, 1): 0.029411764705882353, (2, 2): 0.09558823529411764, (2, 3): 0.5490196078431372, (3, 0): 0.3773049645390071, (3, 1): 0.1127659574468085, (3, 2): 0.5304964539007093, (3, 3): 0.024113475177304965, (4, 0): 0.2932330827067669, (4, 1): 0.4144736842105264, (4, 2): 0.11278195488721807, (4, 3): 0.03383458646616541}\n",
      "k 0\n",
      "conf[k,s] 0.6014150943396226 s 0 best s for k NA\n",
      "conf[k,s] 0.09492924528301885 s 1 best s for k 0\n",
      "conf[k,s] 0.2830188679245283 s 2 best s for k 0\n",
      "conf[k,s] 0.07547169811320753 s 3 best s for k 0\n",
      "k, best s: 0 0\n",
      "MATCH: k 0 s 0\n",
      "\tmax: 0.6014150943396226\n",
      "\tmax 2 + 3: 0.2830188679245283 0.09492924528301885 sum 0.3779481132075472 \n",
      "\n",
      "k 1\n",
      "conf[k,s] 0.17260273972602735 s 0 best s for k NA\n",
      "conf[k,s] 0.3246575342465753 s 1 best s for k 0\n",
      "conf[k,s] 0.09863013698630134 s 2 best s for k 1\n",
      "conf[k,s] 0.14520547945205475 s 3 best s for k 1\n",
      "k, best s: 1 1\n",
      "MATCH: k 1 s 1\n",
      "\tmax: 0.3246575342465753\n",
      "\tmax 2 + 3: 0.17260273972602735 0.14520547945205475 sum 0.3178082191780821 \n",
      "\n",
      "k 2\n",
      "conf[k,s] 0.2647058823529411 s 0 best s for k NA\n",
      "conf[k,s] 0.029411764705882353 s 1 best s for k 0\n",
      "conf[k,s] 0.09558823529411764 s 2 best s for k 0\n",
      "conf[k,s] 0.5490196078431372 s 3 best s for k 0\n",
      "k, best s: 2 3\n",
      "MATCH: k 2 s 3\n",
      "\tmax: 0.5490196078431372\n",
      "\tmax 2 + 3: 0.2647058823529411 0.09558823529411764 sum 0.36029411764705876 \n",
      "\n",
      "k 3\n",
      "conf[k,s] 0.3773049645390071 s 0 best s for k NA\n",
      "conf[k,s] 0.1127659574468085 s 1 best s for k 0\n",
      "conf[k,s] 0.5304964539007093 s 2 best s for k 0\n",
      "conf[k,s] 0.024113475177304965 s 3 best s for k 2\n",
      "k, best s: 3 2\n",
      "MATCH: k 3 s 2\n",
      "\tmax: 0.5304964539007093\n",
      "\tmax 2 + 3: 0.3773049645390071 0.1127659574468085 sum 0.4900709219858156 \n",
      "\n",
      "k 4\n",
      "conf[k,s] 0.2932330827067669 s 0 best s for k NA\n",
      "conf[k,s] 0.4144736842105264 s 1 best s for k 0\n",
      "conf[k,s] 0.11278195488721807 s 2 best s for k 1\n",
      "conf[k,s] 0.03383458646616541 s 3 best s for k 1\n",
      "k, best s: 4 1\n",
      "MATCH: k 4 s 1\n",
      "\tmax: 0.4144736842105264\n",
      "\tmax 2 + 3: 0.2932330827067669 0.11278195488721807 sum 0.40601503759398494 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conf)\n",
    "\n",
    "k_s_match = dict()  # k_s_match[k] = s\n",
    "\n",
    "for k in range(0,number_of_the_k):\n",
    "    print(\"k\",k)\n",
    "    liste_temp = list()\n",
    "    best_s_for_k = \"NA\"\n",
    "    conf[k,best_s_for_k] = -1\n",
    "\n",
    "    \n",
    "    for s in range(0,len(expert_senses)):\n",
    "        print(\"conf[k,s]\",conf[k,s],\"s\",s,\"best s for k\",best_s_for_k)\n",
    "        #print(type(conf[k,s]))\n",
    "        liste_temp.append(conf[k,s])\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            if conf[k,s] > conf[k,best_s_for_k]: \n",
    "                #print(\"NEW best_s:\",s)\n",
    "                best_s_for_k = s\n",
    "                \n",
    "        except KeyError:\n",
    "            print(\"key error should not happen\")\n",
    "        \n",
    "    sorted_liste_temp = sorted(liste_temp, reverse=True)\n",
    "    \n",
    "\n",
    "    \n",
    "# TODO: get the NA to be correct as well\n",
    "    print(\"k, best s:\",k,best_s_for_k)\n",
    "    if conf[k,best_s_for_k] > sorted_liste_temp[1] + sorted_liste_temp[2]: # if the MAX is higher than the sum of the following two\n",
    "        \n",
    "        if conf[k,best_s_for_k] > 1/(len(expert_senses)+1): # if the MAX is higher than the random baseline (number of sense + NA)\n",
    "            k_s_match[k] = best_s_for_k\n",
    "            print(\"MATCH: k\",k,\"s\",best_s_for_k)\n",
    "            print(\"\\tmax:\",sorted_liste_temp[0])\n",
    "            print(\"\\tmax 2 + 3:\",sorted_liste_temp[1],sorted_liste_temp[2],\"sum\",sorted_liste_temp[1]+sorted_liste_temp[2],\"\\n\")\n",
    "            results_file.write(\"MATCH: k %s and s %s \\n\" %(k,best_s_for_k))\n",
    "            \n",
    "        else:\n",
    "            print(\"NO MATCH: k\",k,\"the best s was\",best_s_for_k,\"reason: max < 1/(# of expert senses+1)\")\n",
    "            print(\"\\tmax:\",sorted_liste_temp[0])\n",
    "            print(\"\\tmax 2 + 3:\",sorted_liste_temp[1],sorted_liste_temp[2],\"sum\",sorted_liste_temp[1]+sorted_liste_temp[2],\"\\n\")\n",
    "            k_s_match[k] = \"NA\"\n",
    "    else:\n",
    "        print(\"NO MATCH: k\",k,\"the best s was\",best_s_for_k,\"reason: max < max2+max3\")\n",
    "        print(\"\\tmax 2 + 3:\",sorted_liste_temp[1],sorted_liste_temp[2],\"sum\",sorted_liste_temp[1]+sorted_liste_temp[2],\"\\n\")\n",
    "        k_s_match[k] = \"NA\"\n",
    "        \n",
    "        #if conf[k,best_s_for_k] > 1/(len(expert_senses)+1):\n",
    "         #   print(\"also: reason: max < 1/(# of expert senses+1)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct pairs :\n",
    "\n",
    "- K0 - S0 / S1\n",
    "- K1 - S3 / S1\n",
    "- K2 - S3\n",
    "- K3 - S2\n",
    "- K4 - S0 / S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each s, the k (or more) assigned to it: {0: [0], 1: [1, 4], 3: [2], 2: [3]}\n"
     ]
    }
   ],
   "source": [
    "# For all k->s pair we have in the k_s_match dictionary, we create the inverted dictionary :\n",
    "# s_k_match[s] contains all the k assigned to that s\n",
    "\n",
    "s_k_match = dict()\n",
    "for key in k_s_match.keys():\n",
    "    try: \n",
    "        s_k_match[k_s_match[key]].append(key)\n",
    "        \n",
    "    except KeyError:\n",
    "        s_k_match[k_s_match[key]] = list()\n",
    "        s_k_match[k_s_match[key]].append(key)\n",
    "        \n",
    "print(\"for each s, the k (or more) assigned to it:\",s_k_match)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: How well does the model assign the right words to a given sense of the target word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-473-f315d04cacf9>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-473-f315d04cacf9>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    for each k:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# For each k, we use the words given by the expert as unquestionable truth.\n",
    "# Judging the model's assignment of words to a given sense becomes a question of precision and recall.\n",
    "\n",
    "# precision is all correct w weighted by their respective probabilities / all w weighted by their probabilities\n",
    "\n",
    "for each k:\n",
    "    for each w:\n",
    "        if w in expert_list:\n",
    "            w_weight = p*1\n",
    "            numerator += w_weight\n",
    "        w_weight = p*1\n",
    "        denominator += w_weight\n",
    "    precision = numerator/denominator\n",
    "    \n",
    "# recall is all correct w weighted by their respective probabilities / all w assigned to the sense by the expert\n",
    "for each k:\n",
    "    for each w:\n",
    "        if w in expert_list:\n",
    "            w_weight = p*1\n",
    "            numerator += w_weight\n",
    "    denominator = len(expert_list)\n",
    "    recall = numerator/denominator\n",
    "    \n",
    "# f-score can be used as well\n",
    "\n",
    "for each k:\n",
    "    f_score = 2 * precision * recall / (precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : \n",
    "1. ~~create another word_weight[] only for NA~~\n",
    "2. ~~in this word_weight[], a word that is in an NA (either because w or !=1) has its weight 1/senses, BUT THAT DOES NOT AFFECT THE real word_weight[]~~\n",
    "3. when a k,s match is correctly NA: precision and recall cfr picture\n",
    "\n",
    "ALSO:\n",
    "1. ~~create a s_k_match dictionary that maps s with one or more k assigned by the model. This allows to calculate a new P and R~~\n",
    "2. ~~s_k_match[s] = [kx, ky] (based on matches)~~\n",
    "3. ~~precision and recall for each s, and averaged precisions and recalls as well~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 3, 3: 2, 4: 1}"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_s_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tTHIS IS P and R FOR Ks, WE LOOK AT P and R for Ss now: below\n",
      "\n",
      "\n",
      "\n",
      "For pair ks 0 0 :\n",
      "549\n",
      "The RECALL is 0.7311320754716979 / 524.5 = 0.7652840980628449\n",
      "The PRECISION is 0.7311320754716979 * number of expert words in that sense/ 0.9999999999999999 = 0.731132075471698 \n",
      "\n",
      "The F-SCORE is 0.7478183687637862 \n",
      "\n",
      "For pair ks 1 1 :\n",
      "136\n",
      "The RECALL is 0.4109589041095889 / 41.0 = 1.3631807550952217\n",
      "The PRECISION is 0.4109589041095889 * number of expert words in that sense/ 0.9999999999999997 = 0.410958904109589 \n",
      "\n",
      "The F-SCORE is 0.6315300673322498 \n",
      "\n",
      "For pair ks 2 3 :\n",
      "112\n",
      "The RECALL is 0.5490196078431372 / 101.0 = 0.6088138225587264\n",
      "The PRECISION is 0.5490196078431372 * number of expert words in that sense/ 0.9999999999999999 = 0.5490196078431373 \n",
      "\n",
      "The F-SCORE is 0.5773727331308111 \n",
      "\n",
      "For pair ks 3 2 :\n",
      "193\n",
      "The RECALL is 0.6170212765957448 / 171.5 = 0.6943737981514796\n",
      "The PRECISION is 0.6170212765957448 * number of expert words in that sense/ 1.0000000000000002 = 0.6170212765957447 \n",
      "\n",
      "The F-SCORE is 0.6534162215801302 \n",
      "\n",
      "For pair ks 4 1 :\n",
      "136\n",
      "The RECALL is 0.5789473684210527 / 41.0 = 1.9204107830551989\n",
      "The PRECISION is 0.5789473684210527 * number of expert words in that sense/ 1.0 = 0.5789473684210527 \n",
      "\n",
      "The F-SCORE is 0.8896818316978888 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision_recall_k = dict()\n",
    "\n",
    "print(\"\\t\\t\\tTHIS IS P and R FOR Ks, WE LOOK AT P and R for Ss now: below\\n\\n\\n\")\n",
    "\n",
    "for key in k_s_match.keys():\n",
    "    precision_recall_k[key] = list() # this list has first the recall then the precision then the f score\n",
    "    numerator_recall = 0\n",
    "    denominator_precision = 0\n",
    "    numerator_precision = 0\n",
    "    denominator_recall = 0\n",
    "   # print()\n",
    "\n",
    "\n",
    "\n",
    "############# NEED TO ADJUST FOR PAIRS THAT ARE NAs  --> actually no\n",
    "\n",
    "\n",
    "    if k_s_match[key] == \"NA\":\n",
    "        print(\"K\",key,\"s is NA\")\n",
    "\n",
    "    else: \n",
    "    \n",
    "        for word in k_words_with_prob[int(key)]: \n",
    "            w_weight_precision = k_words_with_prob[int(key)][word] * 1\n",
    "            denominator_precision += float(w_weight_precision)\n",
    "        \n",
    "        \n",
    "        \n",
    "            if word in dict_of_words[expert_senses[int(k_s_match[key])]]:   \n",
    "                w_weight_recall = k_words_with_prob[int(key)][word] * 1\n",
    "                numerator_recall += float(w_weight_recall)\n",
    "\n",
    "                numerator_precision += float(w_weight_precision)\n",
    "    \n",
    "        for mot in dict_of_words[expert_senses[int(k_s_match[key])]]:\n",
    "            denominator_recall += word_weight[mot]\n",
    "        \n",
    "\n",
    "    #denominator_recall = len(dict_of_words[expert_senses[int(key[2])]])\n",
    "    #numerator_recall = numerator_recall*10\n",
    "     \n",
    "    \n",
    "        print(\"For pair ks\",key,k_s_match[key],\":\")\n",
    "        recall = numerator_recall*1/denominator_recall\n",
    "        recall = recall*len(dict_of_words[expert_senses[k_s_match[key]]])\n",
    "    \n",
    "        precision_recall_k[key].append(recall)\n",
    "    \n",
    "        print(len(dict_of_words[expert_senses[k_s_match[key]]]))\n",
    "        print(\"The RECALL is\",numerator_recall,\"/\",denominator_recall,\"=\",recall) \n",
    "        if numerator_precision == 0:\n",
    "            print(\"The PRECISION IS NA\")\n",
    "        else:\n",
    "            precision = numerator_precision/denominator_precision\n",
    "            print(\"The PRECISION is\",numerator_precision,\"* number of expert words in that sense/\",denominator_precision,\"=\",precision,\"\\n\")\n",
    "            precision_recall_k[key].append(precision)\n",
    "        \n",
    "        if (numerator_precision/denominator_precision)+(numerator_recall/denominator_recall) != 0: \n",
    "            fscore = (2*(precision)*(recall)/((precision)+(recall)))\n",
    "            print(\"The F-SCORE is\", fscore,\"\\n\")\n",
    "            precision_recall_k[key].append(fscore)\n",
    "        \n",
    "        else:\n",
    "            print(\"No F-SCORE, can't divide by 0\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P and R based on S, with adapted word weight for NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0], 1: [1, 4], 3: [2], 2: [3]}\n",
      "s and k: 0 [0]\n",
      "s_k_match[key][any_k] 0\n",
      "k_words_with_prob[any_k] {'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075, '64448': 0.05424528301886792, '45980': 0.042452830188679236, '53826': 0.04009433962264151}\n",
      "num precision 0.7311320754716979 for s 0 and a total of 1 k\n",
      "denom precision 0.9999999999999999 for s 0 and a total of 1 k\n",
      "num recall 0.7311320754716979 for s 0 and a total of 1 k\n",
      "denom recall 524.5 for s 0 and a total of 1 k\n",
      "recall: 0.7652840980628449\n",
      "precision: 0.731132075471698\n",
      "fscore: 0.7478183687637862\n",
      "\n",
      "\n",
      "s and k: 1 [1, 4]\n",
      "s_k_match[key][any_k] 1\n",
      "k_words_with_prob[any_k] {'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075, '64448': 0.05424528301886792, '45980': 0.042452830188679236, '53826': 0.04009433962264151}\n",
      "s_k_match[key][any_k] 4\n",
      "k_words_with_prob[any_k] {'79223': 0.17260273972602735, '92927': 0.1561643835616438, '46574': 0.10410958904109587, '67660': 0.10410958904109587, '103085': 0.09863013698630134, '86112': 0.08219178082191778, '101982': 0.07945205479452053, '75808': 0.07123287671232874, '68539': 0.06575342465753423, '54607': 0.06575342465753423}\n",
      "num precision 0.6562419229775135 for s 1 and a total of 2 k\n",
      "denom precision 1.9999999999999996 for s 1 and a total of 2 k\n",
      "num recall 0.6562419229775135 for s 1 and a total of 2 k\n",
      "denom recall 220.83333333333337 for s 1 and a total of 2 k\n",
      "recall: 0.40414596916954787\n",
      "precision: 0.3281209614887568\n",
      "fscore: 0.3621869524177551\n",
      "\n",
      "\n",
      "s and k: 3 [2]\n",
      "s_k_match[key][any_k] 2\n",
      "k_words_with_prob[any_k] {'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075, '64448': 0.05424528301886792, '45980': 0.042452830188679236, '53826': 0.04009433962264151}\n",
      "num precision 0.205188679245283 for s 3 and a total of 1 k\n",
      "denom precision 0.9999999999999999 for s 3 and a total of 1 k\n",
      "num recall 0.205188679245283 for s 3 and a total of 1 k\n",
      "denom recall 101.0 for s 3 and a total of 1 k\n",
      "recall: 0.22753596114328412\n",
      "precision: 0.20518867924528303\n",
      "fscore: 0.21578527770395958\n",
      "\n",
      "\n",
      "s and k: 2 [3]\n",
      "s_k_match[key][any_k] 3\n",
      "k_words_with_prob[any_k] {'28355': 0.2075471698113207, '69419': 0.16273584905660377, '57460': 0.1320754716981132, '114587': 0.0990566037735849, '42071': 0.09669811320754716, '35267': 0.08254716981132075, '51647': 0.08254716981132075, '64448': 0.05424528301886792, '45980': 0.042452830188679236, '53826': 0.04009433962264151}\n",
      "num precision 0.3915094339622641 for s 2 and a total of 1 k\n",
      "denom precision 0.9999999999999999 for s 2 and a total of 1 k\n",
      "num recall 0.3915094339622641 for s 2 and a total of 1 k\n",
      "denom recall 171.5 for s 2 and a total of 1 k\n",
      "recall: 0.44059079157269376\n",
      "precision: 0.3915094339622642\n",
      "fscore: 0.4146025830162798\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision_recall_s = dict()\n",
    "print(s_k_match)\n",
    "#print(dict_of_words)\n",
    "\n",
    "for key in s_k_match.keys():\n",
    "    precision_recall_s[key] = list() # this list has first the recall then the precision then the f score\n",
    "    numerator_recall = 0\n",
    "    denominator_precision = 0\n",
    "    numerator_precision = 0\n",
    "    denominator_recall = 0\n",
    "   # print()\n",
    "    print(\"s and k:\",key,s_k_match[key])\n",
    "    \n",
    "    for any_k in range(0,len(s_k_match[key])):\n",
    "        #print(\"s\",key,\"k\",s_k_match[key],s_k_match[key][any_k])\n",
    "        print(\"s_k_match[key][any_k]\",s_k_match[key][any_k])\n",
    "    \n",
    "        if key == \"NA\":\n",
    "            print(\"s\",key,\"k is NA\")\n",
    "            print(\"this uses a different word_weight\")\n",
    "            \n",
    "            for word in k_words_with_prob[any_k]:\n",
    "                #print(\"finding the NAs\")\n",
    "                w_weight_precision = k_words_with_prob[any_k][word] * 1\n",
    "                denominator_precision += float(w_weight_precision)\n",
    "                \n",
    "                print(word,key)\n",
    "                if word in dict_of_words[expert_senses[key]]:\n",
    "                    #print(\"this word is in k\",any_k,\"and in sense\",expert_senses[key],word)\n",
    "                    w_weight_precision = k_words_with_prob[any_k][word] * 1\n",
    "                    w_weight_recall = k_words_with_prob[any_k][word] * 1\n",
    "                    numerator_precision += float(w_weight_precision)\n",
    "                    numerator_recall += float(w_weight_recall)\n",
    "                \n",
    "\n",
    "        else:\n",
    "            print(\"k_words_with_prob[any_k]\",k_words_with_prob[any_k])\n",
    "            for word in k_words_with_prob[any_k]:\n",
    "\n",
    "                #print(s_k_match[key],s_k_match[key][any_k],word)\n",
    "                \n",
    "                #print(\"\\tdict_of_words[expert_senses[s_k_match[key][any_k]]]\")\n",
    "                #print(\"expert sense\",expert_senses[s_k_match[key][any_k]])\n",
    "                #print(dict_of_words[expert_senses[s_k_match[key][any_k]]])\n",
    "                \n",
    "                w_weight_precision = k_words_with_prob[any_k][word] * 1\n",
    "                denominator_precision += float(w_weight_precision)\n",
    "                \n",
    "                \n",
    "                if word in dict_of_words[expert_senses[key]]:\n",
    "                    #print(\"this word is in k\",any_k,\"and in sense\",expert_senses[key],word)\n",
    "                    w_weight_precision = k_words_with_prob[any_k][word] * 1\n",
    "                    w_weight_recall = k_words_with_prob[any_k][word] * 1\n",
    "                    numerator_precision += float(w_weight_precision)\n",
    "                    numerator_recall += float(w_weight_recall)\n",
    "        \n",
    "        \n",
    "        ### SINCE WE HAVE the possibility of having two (or more) k for each s, the expert s words should be counted k times\n",
    "        \n",
    "        if expert_senses[key] != \"NA\":\n",
    "            for mot in dict_of_words[expert_senses[key]]:\n",
    "                denominator_recall += word_weight[mot]\n",
    "                \n",
    "        if expert_senses[key] == \"NA\":\n",
    "            for mot in dict_of_words[expert_senses[key]]:\n",
    "                denominator_recall += word_weight_NA[mot]\n",
    "                \n",
    "    #if key != \"NA\":\n",
    "    \n",
    "    recall = numerator_recall*1/denominator_recall\n",
    "    recall = recall*len(dict_of_words[expert_senses[key]])\n",
    "    precision_recall_s[key].append(recall)\n",
    "        \n",
    "    precision = numerator_precision/denominator_precision\n",
    "    precision_recall_s[key].append(precision)\n",
    "        \n",
    "    fscore = (2*(precision)*(recall)/((precision)+(recall)))\n",
    "    precision_recall_s[key].append(fscore)\n",
    "        \n",
    "   # else: # this must be changed for NAs\n",
    "        #precision_recall_s[key].append(0)\n",
    "    \n",
    "                    \n",
    "    print(\"num precision\",numerator_precision,\"for s\",key,\"and a total of\",len(s_k_match[key]),\"k\")\n",
    "    print(\"denom precision\",denominator_precision,\"for s\",key,\"and a total of\",len(s_k_match[key]),\"k\")\n",
    "    print(\"num recall\",numerator_recall,\"for s\",key,\"and a total of\",len(s_k_match[key]),\"k\")\n",
    "    print(\"denom recall\",denominator_recall,\"for s\",key,\"and a total of\",len(s_k_match[key]),\"k\")\n",
    "    print(\"recall:\",recall)\n",
    "    print(\"precision:\",precision)\n",
    "    print(\"fscore:\",fscore)\n",
    "    results_file.write(\"SCORES FOR PAIR S= %s <-> {K...K}= %s: P%s R%s F%s \\n\\n\" %(key,s_k_match[key],precision,recall,fscore))\n",
    "        \n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.7652840980628449, 0.731132075471698, 0.7478183687637862], 1: [1.3631807550952217, 0.410958904109589, 0.6315300673322498], 2: [0.6088138225587264, 0.5490196078431373, 0.5773727331308111], 3: [0.6943737981514796, 0.6170212765957447, 0.6534162215801302], 4: [1.9204107830551989, 0.5789473684210527, 0.8896818316978888]}\n",
      "AVERAGED SCORES BASED ON Ks:\n",
      "averaged recall =  1.0704126513846943\n",
      "averaged precision =  0.5774158464882444\n",
      "averaged fscore =  0.6999638445009733\n",
      "\n",
      "\n",
      "{0: [0.7652840980628449, 0.731132075471698, 0.7478183687637862], 1: [0.40414596916954787, 0.3281209614887568, 0.3621869524177551], 3: [0.22753596114328412, 0.20518867924528303, 0.21578527770395958], 2: [0.44059079157269376, 0.3915094339622642, 0.4146025830162798]}\n",
      "AVERAGED SCORES BASED ON Ss:\n",
      "averaged recall =  0.4593892049870927\n",
      "averaged precision =  0.4139877875420005\n",
      "averaged fscore =  0.43509829547544515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(precision_recall_k)\n",
    "total_recall = 0\n",
    "total_precision = 0\n",
    "total_fscore = 0\n",
    "for key in precision_recall_k:\n",
    "    try:\n",
    "        total_recall += precision_recall_k[key][0]\n",
    "    except IndexError:\n",
    "        print(\"nothing for k\",key)\n",
    "    try: \n",
    "        total_precision += precision_recall_k[key][1]\n",
    "    except IndexError:\n",
    "        print(\"nothing for k\",key)\n",
    "        \n",
    "    try: \n",
    "        total_fscore += precision_recall_k[key][2]\n",
    "    except IndexError:\n",
    "        print(\"nothing for k\",key)\n",
    "        \n",
    "        \n",
    "print(\"AVERAGED SCORES BASED ON Ks:\")    \n",
    "print(\"averaged recall = \",total_recall/number_of_the_k)\n",
    "print(\"averaged precision = \",total_precision/number_of_the_k)\n",
    "print(\"averaged fscore = \",total_fscore/number_of_the_k)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(precision_recall_s)\n",
    "total_recall = 0\n",
    "total_precision = 0\n",
    "total_fscore = 0\n",
    "for key in precision_recall_s:\n",
    "    try:\n",
    "        total_recall += precision_recall_s[key][0]\n",
    "    except IndexError:\n",
    "        print(\"nothing for s\",key)\n",
    "    try: \n",
    "        total_precision += precision_recall_s[key][1]\n",
    "    except IndexError:\n",
    "        print(\"nothing for s\",key)\n",
    "        \n",
    "    try: \n",
    "        total_fscore += precision_recall_s[key][2]\n",
    "    except IndexError:\n",
    "        print(\"nothing for s\",key)\n",
    "        \n",
    "\n",
    "\n",
    "print(\"AVERAGED SCORES BASED ON Ss:\")    \n",
    "print(\"averaged recall = \",total_recall/len(expert_senses))  # or should I divide by the number of Ks?\n",
    "print(\"averaged precision = \",total_precision/len(expert_senses))\n",
    "print(\"averaged fscore = \",total_fscore/len(expert_senses))\n",
    "results_file.write(\"Averaged scores: precision = %s recall %s fscore %s\\n\\n\" %(total_precision/len(expert_senses),total_recall/len(expert_senses),total_fscore/len(expert_senses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mus-1', 'NA', 'mus-4', 'mus-2']\n"
     ]
    }
   ],
   "source": [
    "print(expert_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in expert_senses:\n",
    "    #print(i,dict_of_words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qx: Model(s) comparison against annotated subcorpus (sense importance evolution + sense emergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-429, -428, -427, -426, -425, -424, -423, -422, -421, -420, -419, -418, -417, -416, -415, -414, -413, -412, -411, -410, -409, -408, -407, -406, -405, -404, -403, -402, -401, -400, -399, -398, -397, -396, -395, -394, -393, -392, -391, -390, -389, -388, -387, -386, -385, -384, -383, -382, -381, -380, -379, -378, -377, -376, -375, -374, -373, -372, -371, -370, -369, -368, -367, -366, -365, -364, -363, -362, -361, -360, -359, -358, -357, -356, -355, -354, -353, -352, -351, -350, -349, -348, -347, -346, -345, -344, -343, -342, -341, -340, -339, -338, -337, -336, -335, -334, -333, -332, -331] \n",
      "\n",
      "1 [-329, -328, -327, -326, -325, -324, -323, -322, -321, -320, -319, -318, -317, -316, -315, -314, -313, -312, -311, -310, -309, -308, -307, -306, -305, -304, -303, -302, -301, -300, -299, -298, -297, -296, -295, -294, -293, -292, -291, -290, -289, -288, -287, -286, -285, -284, -283, -282, -281, -280, -279, -278, -277, -276, -275, -274, -273, -272, -271, -270, -269, -268, -267, -266, -265, -264, -263, -262, -261, -260, -259, -258, -257, -256, -255, -254, -253, -252, -251, -250, -249, -248, -247, -246, -245, -244, -243, -242, -241, -240, -239, -238, -237, -236, -235, -234, -233, -232, -231] \n",
      "\n",
      "2 [-229, -228, -227, -226, -225, -224, -223, -222, -221, -220, -219, -218, -217, -216, -215, -214, -213, -212, -211, -210, -209, -208, -207, -206, -205, -204, -203, -202, -201, -200, -199, -198, -197, -196, -195, -194, -193, -192, -191, -190, -189, -188, -187, -186, -185, -184, -183, -182, -181, -180, -179, -178, -177, -176, -175, -174, -173, -172, -171, -170, -169, -168, -167, -166, -165, -164, -163, -162, -161, -160, -159, -158, -157, -156, -155, -154, -153, -152, -151, -150, -149, -148, -147, -146, -145, -144, -143, -142, -141, -140, -139, -138, -137, -136, -135, -134, -133, -132, -131] \n",
      "\n",
      "3 [-129, -128, -127, -126, -125, -124, -123, -122, -121, -120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31] \n",
      "\n",
      "4 [-29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] \n",
      "\n",
      "5 [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169] \n",
      "\n",
      "6 [169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in slice_years.keys():\n",
    "    print(key,slice_years[key],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the number of hits per sense per period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sense_date_amount = dict()\n",
    "\n",
    "for sense in sense_year.keys():\n",
    "   \n",
    "    print(\"Sense:\",sense)\n",
    "    counter = 0\n",
    "    for i in range(0,number_of_slices):\n",
    "        #print(\"period\",i,\"years for that sense in that period\",sense_year[sense])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(sense_year[sense])\n",
    "        for year in sense_year[sense]:\n",
    "        \n",
    "            if year in slice_years[i]:\n",
    "                counter += 1\n",
    "                #print(sense_year[sense][i])\n",
    "                \n",
    "        sense_date_amount[sense,i] = counter           \n",
    "    print(sense,counter)\n",
    "    \n",
    "print(sense_date_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the relative number of hits per sense per period\n",
    "(for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total period {0: 28, 1: 4, 2: 1, 3: 4, 4: 7, 5: 25, 6: 79}\n",
      "sense date amount {('mus-1', 0): 7, ('mus-1', 1): 3, ('mus-1', 2): 1, ('mus-1', 3): 3, ('mus-1', 4): 7, ('mus-1', 5): 24, ('mus-1', 6): 48, ('NA', 0): 0, ('NA', 1): 0, ('NA', 2): 0, ('NA', 3): 0, ('NA', 4): 0, ('NA', 5): 0, ('NA', 6): 0, ('mus-4', 0): 21, ('mus-4', 1): 1, ('mus-4', 2): 0, ('mus-4', 3): 1, ('mus-4', 4): 0, ('mus-4', 5): 1, ('mus-4', 6): 9, ('mus-2', 0): 0, ('mus-2', 1): 0, ('mus-2', 2): 0, ('mus-2', 3): 0, ('mus-2', 4): 0, ('mus-2', 5): 0, ('mus-2', 6): 22}\n",
      "('mus-1', 0) total for this sense at this period 7 total period 28\n",
      "relative 0.25\n",
      "('mus-1', 1) total for this sense at this period 3 total period 4\n",
      "relative 0.75\n",
      "('mus-1', 2) total for this sense at this period 1 total period 1\n",
      "relative 1.0\n",
      "('mus-1', 3) total for this sense at this period 3 total period 4\n",
      "relative 0.75\n",
      "('mus-1', 4) total for this sense at this period 7 total period 7\n",
      "relative 1.0\n",
      "('mus-1', 5) total for this sense at this period 24 total period 25\n",
      "relative 0.96\n",
      "('mus-1', 6) total for this sense at this period 48 total period 79\n",
      "relative 0.6075949367088608\n",
      "('NA', 0) total for this sense at this period 0 total period 28\n",
      "relative 0.0\n",
      "('NA', 1) total for this sense at this period 0 total period 4\n",
      "relative 0.0\n",
      "('NA', 2) total for this sense at this period 0 total period 1\n",
      "relative 0.0\n",
      "('NA', 3) total for this sense at this period 0 total period 4\n",
      "relative 0.0\n",
      "('NA', 4) total for this sense at this period 0 total period 7\n",
      "relative 0.0\n",
      "('NA', 5) total for this sense at this period 0 total period 25\n",
      "relative 0.0\n",
      "('NA', 6) total for this sense at this period 0 total period 79\n",
      "relative 0.0\n",
      "('mus-4', 0) total for this sense at this period 21 total period 28\n",
      "relative 0.75\n",
      "('mus-4', 1) total for this sense at this period 1 total period 4\n",
      "relative 0.25\n",
      "('mus-4', 2) total for this sense at this period 0 total period 1\n",
      "relative 0.0\n",
      "('mus-4', 3) total for this sense at this period 1 total period 4\n",
      "relative 0.25\n",
      "('mus-4', 4) total for this sense at this period 0 total period 7\n",
      "relative 0.0\n",
      "('mus-4', 5) total for this sense at this period 1 total period 25\n",
      "relative 0.04\n",
      "('mus-4', 6) total for this sense at this period 9 total period 79\n",
      "relative 0.11392405063291139\n",
      "('mus-2', 0) total for this sense at this period 0 total period 28\n",
      "relative 0.0\n",
      "('mus-2', 1) total for this sense at this period 0 total period 4\n",
      "relative 0.0\n",
      "('mus-2', 2) total for this sense at this period 0 total period 1\n",
      "relative 0.0\n",
      "('mus-2', 3) total for this sense at this period 0 total period 4\n",
      "relative 0.0\n",
      "('mus-2', 4) total for this sense at this period 0 total period 7\n",
      "relative 0.0\n",
      "('mus-2', 5) total for this sense at this period 0 total period 25\n",
      "relative 0.0\n",
      "('mus-2', 6) total for this sense at this period 22 total period 79\n",
      "relative 0.27848101265822783\n",
      "{('mus-1', 0): 0.25, ('mus-1', 1): 0.75, ('mus-1', 2): 1.0, ('mus-1', 3): 0.75, ('mus-1', 4): 1.0, ('mus-1', 5): 0.96, ('mus-1', 6): 0.6075949367088608, ('NA', 0): 0.0, ('NA', 1): 0.0, ('NA', 2): 0.0, ('NA', 3): 0.0, ('NA', 4): 0.0, ('NA', 5): 0.0, ('NA', 6): 0.0, ('mus-4', 0): 0.75, ('mus-4', 1): 0.25, ('mus-4', 2): 0.0, ('mus-4', 3): 0.25, ('mus-4', 4): 0.0, ('mus-4', 5): 0.04, ('mus-4', 6): 0.11392405063291139, ('mus-2', 0): 0.0, ('mus-2', 1): 0.0, ('mus-2', 2): 0.0, ('mus-2', 3): 0.0, ('mus-2', 4): 0.0, ('mus-2', 5): 0.0, ('mus-2', 6): 0.27848101265822783}\n",
      "mus-1 0 0.25\n",
      "NA 0 0.0\n",
      "mus-4 0 0.75\n",
      "mus-2 0 0.0\n",
      "mus-1 1 0.75\n",
      "NA 1 0.0\n",
      "mus-4 1 0.25\n",
      "mus-2 1 0.0\n",
      "mus-1 2 1.0\n",
      "NA 2 0.0\n",
      "mus-4 2 0.0\n",
      "mus-2 2 0.0\n",
      "mus-1 3 0.75\n",
      "NA 3 0.0\n",
      "mus-4 3 0.25\n",
      "mus-2 3 0.0\n",
      "mus-1 4 1.0\n",
      "NA 4 0.0\n",
      "mus-4 4 0.0\n",
      "mus-2 4 0.0\n",
      "mus-1 5 0.96\n",
      "NA 5 0.0\n",
      "mus-4 5 0.04\n",
      "mus-2 5 0.0\n",
      "mus-1 6 0.6075949367088608\n",
      "NA 6 0.0\n",
      "mus-4 6 0.11392405063291139\n",
      "mus-2 6 0.27848101265822783\n",
      "{0: [0.25, 0.0, 0.75, 0.0], 1: [0.75, 0.0, 0.25, 0.0], 2: [1.0, 0.0, 0.0, 0.0], 3: [0.75, 0.0, 0.25, 0.0], 4: [1.0, 0.0, 0.0, 0.0], 5: [0.96, 0.0, 0.04, 0.0], 6: [0.6075949367088608, 0.0, 0.11392405063291139, 0.27848101265822783]}\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "total_period = dict()\n",
    "\n",
    "sense_period_relative = dict()\n",
    "\n",
    "for i in range(0,number_of_slices):\n",
    "    for entry in expert_senses:\n",
    "        \n",
    "# for period i we store for each sense the number of times the sense is seen\n",
    "        \n",
    "        try:\n",
    "            total_period[i] += sense_date_amount[entry,i]\n",
    "        except KeyError:\n",
    "            total_period[i] = 0\n",
    "            total_period[i] += sense_date_amount[entry,i]\n",
    "            \n",
    "        #print(i,entry,\"+\",sense_date_amount[entry,i],\"=\",total_period[i])\n",
    "        \n",
    "        \n",
    "print(\"total period\",total_period)\n",
    "print(\"sense date amount\",sense_date_amount)\n",
    "        \n",
    "for key in sense_date_amount:\n",
    "    \n",
    "    # for each (sense,period) pair we divide the number by the total number of words at that period\n",
    "    \n",
    "    print(key,\"total for this sense at this period\",sense_date_amount[key],\"total period\",total_period[key[1]])\n",
    "    \n",
    "    sense_period_relative[key] = float(sense_date_amount[key]/total_period[key[1]])\n",
    "    print(\"relative\",sense_period_relative[key])\n",
    "  \n",
    "print(sense_period_relative)        \n",
    "\n",
    "period_relative = dict()\n",
    "temp_list = list()\n",
    "\n",
    "for i in range(0,number_of_slices):\n",
    "    temp_list = list()\n",
    "    for entry in expert_senses:\n",
    "        if len(temp_list) < len(expert_senses):\n",
    "            temp_list.append(sense_period_relative[entry,i])\n",
    "            print(entry,i,sense_period_relative[entry,i])\n",
    "        \n",
    "    period_relative[i] = temp_list\n",
    "        \n",
    "        \n",
    "print(period_relative)\n",
    "print(number_of_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting expert annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 3, 3: 2, 4: 1}"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_s_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period 0 [25, 0, 75, 0]\n",
      "Period 1 [75, 0, 25, 0]\n",
      "Period 2 [100, 0, 0, 0]\n",
      "Period 3 [75, 0, 25, 0]\n",
      "Period 4 [100, 0, 0, 0]\n",
      "Period 5 [96, 0, 4, 0]\n",
      "Period 6 [60, 0, 11, 27]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "valeurs = period_relative\n",
    "colours = ['b','g','r','c','m','y','k'] #to make sure colours remain the same throughout all slices\n",
    "\n",
    "valeurs2 = dict()\n",
    "\n",
    "for key in valeurs.keys():\n",
    "    #print(key)\n",
    "    key2 = \"Period \"+str(key)\n",
    "    list_temp = list()\n",
    "    for item in valeurs[key]:\n",
    "        list_temp.append(int(item*100))   # let's have percentages and not .xx\n",
    "    valeurs2[key2] = list_temp\n",
    "\n",
    "    #for value in valeurs\n",
    "    \n",
    "\n",
    "for key,vals in valeurs2.items():\n",
    "    print(key,vals)\n",
    "    \n",
    "    for i in range(0,len(vals)):        \n",
    "        if i == 0:\n",
    "            previous = 0\n",
    "            plt.bar(x=key, height=vals[i],bottom=previous,color=colours[i])\n",
    "            \n",
    "        else:         \n",
    "            previous = vals[i-1] + previous\n",
    "            plt.bar(x=key, height=vals[i],bottom=previous,color=colours[i])\n",
    "            \n",
    "plt.xticks(range(len(valeurs2)), valeurs2.keys())\n",
    "\n",
    "expert_image = s_senses.name.split(\"/\")[-1]\n",
    "\n",
    "#plt.figure(figsize=(20,10))\n",
    "image = plt.gcf()\n",
    "image.savefig(dir_out+\"/\"+expert_image+\".png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Period 0', 'Period 1', 'Period 2', 'Period 3', 'Period 4', 'Period 5', 'Period 6'])\n"
     ]
    }
   ],
   "source": [
    "print(valeurs2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 3, 3: 2, 4: 1}\n",
      "Period 0 [25, 0, 75, 0]\n",
      "<class 'str'> <class 'list'>\n",
      "expert sense 0 = 25 has the colour b\n",
      "expert sense 1 = 0 has the colour g\n",
      "expert sense 2 = 75 has the colour r\n",
      "expert sense 3 = 0 has the colour c\n",
      "Period 1 [75, 0, 25, 0]\n",
      "<class 'str'> <class 'list'>\n",
      "expert sense 0 = 75 has the colour b\n",
      "expert sense 1 = 0 has the colour g\n",
      "expert sense 2 = 25 has the colour r\n",
      "expert sense 3 = 0 has the colour c\n",
      "Period 2 [100, 0, 0, 0]\n",
      "<class 'str'> <class 'list'>\n",
      "expert sense 0 = 100 has the colour b\n",
      "expert sense 1 = 0 has the colour g\n",
      "expert sense 2 = 0 has the colour r\n",
      "expert sense 3 = 0 has the colour c\n",
      "Period 3 [75, 0, 25, 0]\n",
      "<class 'str'> <class 'list'>\n",
      "expert sense 0 = 75 has the colour b\n",
      "expert sense 1 = 0 has the colour g\n",
      "expert sense 2 = 25 has the colour r\n",
      "expert sense 3 = 0 has the colour c\n",
      "Period 4 [100, 0, 0, 0]\n",
      "<class 'str'> <class 'list'>\n",
      "expert sense 0 = 100 has the colour b\n",
      "expert sense 1 = 0 has the colour g\n",
      "expert sense 2 = 0 has the colour r\n",
      "expert sense 3 = 0 has the colour c\n",
      "Period 5 [96, 0, 4, 0]\n",
      "<class 'str'> <class 'list'>\n",
      "expert sense 0 = 96 has the colour b\n",
      "expert sense 1 = 0 has the colour g\n",
      "expert sense 2 = 4 has the colour r\n",
      "expert sense 3 = 0 has the colour c\n",
      "Period 6 [60, 0, 11, 27]\n",
      "<class 'str'> <class 'list'>\n",
      "expert sense 0 = 60 has the colour b\n",
      "expert sense 1 = 0 has the colour g\n",
      "expert sense 2 = 11 has the colour r\n",
      "expert sense 3 = 27 has the colour c\n"
     ]
    }
   ],
   "source": [
    "print(k_s_match)\n",
    "\n",
    "for key,vals in valeurs2.items():\n",
    "    print(key,vals)\n",
    "    print(type(key),type(vals))\n",
    "    for i in range(0,len(vals)):\n",
    "        print(\"expert sense\",i,\"=\",vals[i],\"has the colour\",colours[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "liste_number_year = list() # creating a list because matplotlib wants a tuple\n",
    "for key in sense_date_amount.keys():\n",
    "    #print(key)\n",
    "    liste_number_year.append(sense_date_amount[key])\n",
    "    \n",
    "tuple_number_year = tuple(liste_number_year)\n",
    "#print(tuple_number_year)\n",
    "\n",
    "period_number = dict()\n",
    "\n",
    "for key in sense_date_amount.keys():\n",
    "    compteur = 0\n",
    "    if key[1] in range(0,number_of_slices):\n",
    "        print(key,sense_date_amount[key[0],key[1]])\n",
    "        compteur += sense_date_amount[key[0],key[1]]\n",
    "        \n",
    "        try :\n",
    "            period_number[key[1]] += compteur\n",
    "        except KeyError:\n",
    "            period_number[key[1]] = 0\n",
    "            period_number[key[1]] += compteur\n",
    "            \n",
    "        \n",
    "for entry in period_number:\n",
    "    print(\"période\",entry,\"number of uses\",period_number[entry])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading model output for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_output_plot = output_senses.split(\"===============  per time  ===============\")[1].split(\"\\n\")\n",
    "period_relative_model = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(lines_output_plot)):\n",
    "    if lines_output_plot[i][0:5] == \"Time=\":  # if a line starts with \"time\" we take it into account\n",
    "        for x in range(i,i+number_of_the_k+1): # for every \"number of  the k\" lines that follow\n",
    "            #print(lines_output_plot[x])\n",
    "            if lines_output_plot[x][0:5] == \"Time=\": # if a line starts with \"time\" we take the value for the slice\n",
    "                period = lines_output_plot[x][5:6]\n",
    "                templist = list()\n",
    "                \n",
    "            if lines_output_plot[x][0:5] != \"Time=\":  # if a line doesn't start with \"time\" but is considered(cf line3)\n",
    "                ligne = re.split(\"\\s{3,}\",lines_output_plot[x]) # we take the first part of the line (importance of that K)\n",
    "                templist.append(float(ligne[0]))\n",
    "            #print(period,templist)\n",
    "            \n",
    "        period_relative_model[str(period)] = templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': [0.04083955068731151, 0.008486796949771783, 0.00597187964362235, 0.7697746391951782, 0.17492713352411612], '1': [0.10907371060119478, 0.014298730684103153, 0.03384641373162034, 0.5064813344844331, 0.3362998104986487], '2': [0.08757407290535785, 0.015051254608967434, 0.024163835560131568, 0.6984925663043847, 0.17471827062115847], '3': [0.07407106626171724, 0.03404926797763053, 0.04501432410891889, 0.6654202704667155, 0.18144507118501788], '4': [0.1803754795434305, 0.04005687932522156, 0.10369804638106733, 0.43394041107060427, 0.24192918367967622], '5': [0.17698941573659951, 0.03704265374613105, 0.14841983538917458, 0.41587711391800924, 0.2216709812100856], '6': [0.20603546151577476, 0.0777841384954993, 0.2523433469634035, 0.3203623104634722, 0.14347474256185028]}\n"
     ]
    }
   ],
   "source": [
    "print(period_relative_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting model output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period 0 [0.04083955068731151, 0.008486796949771783, 0.00597187964362235, 0.7697746391951782, 0.17492713352411612]\n",
      "<class 'str'> <class 'list'>\n",
      "0 b\n",
      "1 g\n",
      "1 g\n",
      "2 r\n",
      "3 c\n",
      "Period 1 [0.10907371060119478, 0.014298730684103153, 0.03384641373162034, 0.5064813344844331, 0.3362998104986487]\n",
      "<class 'str'> <class 'list'>\n",
      "0 b\n",
      "1 g\n",
      "1 g\n",
      "2 r\n",
      "3 c\n",
      "Period 2 [0.08757407290535785, 0.015051254608967434, 0.024163835560131568, 0.6984925663043847, 0.17471827062115847]\n",
      "<class 'str'> <class 'list'>\n",
      "0 b\n",
      "1 g\n",
      "1 g\n",
      "2 r\n",
      "3 c\n",
      "Period 3 [0.07407106626171724, 0.03404926797763053, 0.04501432410891889, 0.6654202704667155, 0.18144507118501788]\n",
      "<class 'str'> <class 'list'>\n",
      "0 b\n",
      "1 g\n",
      "1 g\n",
      "2 r\n",
      "3 c\n",
      "Period 4 [0.1803754795434305, 0.04005687932522156, 0.10369804638106733, 0.43394041107060427, 0.24192918367967622]\n",
      "<class 'str'> <class 'list'>\n",
      "0 b\n",
      "1 g\n",
      "1 g\n",
      "2 r\n",
      "3 c\n",
      "Period 5 [0.17698941573659951, 0.03704265374613105, 0.14841983538917458, 0.41587711391800924, 0.2216709812100856]\n",
      "<class 'str'> <class 'list'>\n",
      "0 b\n",
      "1 g\n",
      "1 g\n",
      "2 r\n",
      "3 c\n",
      "Period 6 [0.20603546151577476, 0.0777841384954993, 0.2523433469634035, 0.3203623104634722, 0.14347474256185028]\n",
      "<class 'str'> <class 'list'>\n",
      "0 b\n",
      "1 g\n",
      "1 g\n",
      "2 r\n",
      "3 c\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "valeurs = period_relative_model\n",
    "colours = ['b','g','r','c','m','y','k','w'] #to make sure colours remain the same throughout all slices\n",
    "\n",
    "\n",
    "valeurs3 = dict()\n",
    "\n",
    "for key in valeurs.keys():\n",
    "    #print(key)\n",
    "    key2 = \"Period \"+str(key)\n",
    "    list_temp = list()\n",
    "    for item in valeurs[key]:\n",
    "        list_temp.append(item)   \n",
    "    valeurs3[key2] = list_temp\n",
    "\n",
    "\n",
    "\n",
    "for key,vals in valeurs3.items():\n",
    "    print(key,vals)\n",
    "    print(type(key),type(vals))\n",
    "    \n",
    "    for i in range(0,len(vals)):        \n",
    "        if i == 0:\n",
    "            previous = 0\n",
    "            plt.bar(x=key, height=vals[i]*100,bottom=previous*100,color=colours[i])\n",
    "            \n",
    "        else:         \n",
    "            previous = vals[i-1] + previous\n",
    "            plt.bar(x=key, height=vals[i]*100,bottom=previous*100,color=colours[i])\n",
    "            \n",
    "        for value in k_s_match.values():\n",
    "            if i == value: \n",
    "                print(i,colours[i])\n",
    "        \n",
    "plt.xticks(range(len(valeurs3)), valeurs3.keys())\n",
    "\n",
    "#plt.figure(figsize=(20,10))\n",
    "\n",
    "model_image = k_senses.name.split(\"/\")[-1]\n",
    "\n",
    "image = plt.gcf()\n",
    "image.savefig(dir_out+\"/\"+model_image+\".png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 3, 3: 2, 4: 1}\n",
      "Period 0 [0.04083955068731151, 0.008486796949771783, 0.00597187964362235, 0.7697746391951782, 0.17492713352411612]\n",
      "b ===== b\n",
      "g ===== g\n",
      "r ===== c\n",
      "c ===== r\n",
      "m ===== g\n",
      "Period 1 [0.10907371060119478, 0.014298730684103153, 0.03384641373162034, 0.5064813344844331, 0.3362998104986487]\n",
      "b ===== b\n",
      "g ===== g\n",
      "r ===== c\n",
      "c ===== r\n",
      "m ===== g\n",
      "Period 2 [0.08757407290535785, 0.015051254608967434, 0.024163835560131568, 0.6984925663043847, 0.17471827062115847]\n",
      "b ===== b\n",
      "g ===== g\n",
      "r ===== c\n",
      "c ===== r\n",
      "m ===== g\n",
      "Period 3 [0.07407106626171724, 0.03404926797763053, 0.04501432410891889, 0.6654202704667155, 0.18144507118501788]\n",
      "b ===== b\n",
      "g ===== g\n",
      "r ===== c\n",
      "c ===== r\n",
      "m ===== g\n",
      "Period 4 [0.1803754795434305, 0.04005687932522156, 0.10369804638106733, 0.43394041107060427, 0.24192918367967622]\n",
      "b ===== b\n",
      "g ===== g\n",
      "r ===== c\n",
      "c ===== r\n",
      "m ===== g\n",
      "Period 5 [0.17698941573659951, 0.03704265374613105, 0.14841983538917458, 0.41587711391800924, 0.2216709812100856]\n",
      "b ===== b\n",
      "g ===== g\n",
      "r ===== c\n",
      "c ===== r\n",
      "m ===== g\n",
      "Period 6 [0.20603546151577476, 0.0777841384954993, 0.2523433469634035, 0.3203623104634722, 0.14347474256185028]\n",
      "b ===== b\n",
      "g ===== g\n",
      "r ===== c\n",
      "c ===== r\n",
      "m ===== g\n"
     ]
    }
   ],
   "source": [
    "print(k_s_match)\n",
    "\n",
    "for key,vals in valeurs3.items():\n",
    "    print(key,vals)\n",
    "    #print(type(key),type(vals))\n",
    "    for i in range(0,len(vals)):\n",
    "        #print(\"model sense\",i,\"=\",vals[i],\"has the colour\",colours[i])\n",
    "        #print(\"this is the equivalent of\")\n",
    "        if k_s_match[i] != \"NA\":\n",
    "            #print(\"expert sense\",k_s_match[i],colours[int(k_s_match[i])],\"\\n\")\n",
    "            print(colours[i],\"=====\",colours[int(k_s_match[i])])\n",
    "        else:\n",
    "            print(\"NA\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "1. ~~Choose best (k,s) pair~~\n",
    "1. Match k and s in the plots\n",
    "2. Label the plots (senses, slices)\n",
    "2. ~~Remove the \"w\" sense~~\n",
    "3. Confidence interval (less important for now)\n",
    "4. ~~Fix the recall calculation cfr email Valerio 28/03~~\n",
    "5. ~~CHECK PROBABILITIES (conf)~~ \n",
    "6. Write output to file + sync github\n",
    "7. ~~Fix length of time interval (100 vs 113)_~~ ||| earliest date [from parameter_file] vs time interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best pair: the one with the maximum above a certain threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO post meeting with B and V\n",
    "1. plot distribution of senses across genres\n",
    "2. plot distribution of genres across time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO post 10/4 3pm:\n",
    "\n",
    "- ~~when parsing senses_3874965.txt, if mus-x is followed by something else than \"1\", mark the sense as \"NA\"~~\n",
    "- ~~when parsing senses_3874965.txt, add a parameter for window size~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
